{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480d2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-language=cs\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=cs/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n",
      "Using custom data configuration default-language=de\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=de/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n",
      "Using custom data configuration default-language=en\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=en/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n",
      "Using custom data configuration default-language=it\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=it/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n",
      "Using custom data configuration default-language=nl\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=nl/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n",
      "Using custom data configuration default-language=sk\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=sk/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n",
      "Using custom data configuration default-language=cs\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=cs/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n",
      "Using custom data configuration default-language=sk\n",
      "Reusing dataset multi_eurlex (/home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=sk/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import concatenate_datasets\n",
    "langs=[\"cs\",\"de\",\"en\",\"it\",\"nl\",\"sk\"]\n",
    "data_cs= load_dataset(\"multi_eurlex\", language=\"cs\",split='train')\n",
    "data_de= load_dataset(\"multi_eurlex\", language=\"de\",split='train')\n",
    "data_en= load_dataset(\"multi_eurlex\", language=\"en\",split='train')\n",
    "data_it= load_dataset(\"multi_eurlex\", language=\"it\",split='train')\n",
    "data_nl= load_dataset(\"multi_eurlex\", language=\"nl\",split='train')\n",
    "data_sk= load_dataset(\"multi_eurlex\", language=\"sk\",split='train')\n",
    "data_test_cs=load_dataset(\"multi_eurlex\", language=\"cs\",split='test')\n",
    "data_test_sk=load_dataset(\"multi_eurlex\", language=\"sk\",split='test')\n",
    "\n",
    "\n",
    "data_train = concatenate_datasets([data_de, data_en, data_it, data_nl,data_cs, data_sk])  \n",
    "data_test = concatenate_datasets([data_test_sk,data_test_cs])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7ae43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celex_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32006D0213</td>\n",
       "      <td>ENTSCHEIDUNG DER KOMMISSION\\nvom 6. März 2006\\...</td>\n",
       "      <td>[1, 20, 7, 3, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32003R1330</td>\n",
       "      <td>Verordnung (EG) Nr. 1330/2003 der Kommission\\n...</td>\n",
       "      <td>[2, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32003R1786</td>\n",
       "      <td>Verordnung (EG) Nr. 1786/2003 des Rates\\nvom 2...</td>\n",
       "      <td>[3, 19, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31985R2590</td>\n",
       "      <td>*****\\nVERORDNUNG (EWG) Nr. 2590/85 DER KOMMIS...</td>\n",
       "      <td>[12, 17, 19, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31993R1103</td>\n",
       "      <td>VERORDNUNG (EWG) Nr. 1103/93 DER KOMMISSION vo...</td>\n",
       "      <td>[18, 3, 4, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     celex_id                                               text  \\\n",
       "0  32006D0213  ENTSCHEIDUNG DER KOMMISSION\\nvom 6. März 2006\\...   \n",
       "1  32003R1330  Verordnung (EG) Nr. 1330/2003 der Kommission\\n...   \n",
       "2  32003R1786  Verordnung (EG) Nr. 1786/2003 des Rates\\nvom 2...   \n",
       "3  31985R2590  *****\\nVERORDNUNG (EWG) Nr. 2590/85 DER KOMMIS...   \n",
       "4  31993R1103  VERORDNUNG (EWG) Nr. 1103/93 DER KOMMISSION vo...   \n",
       "\n",
       "             labels  \n",
       "0  [1, 20, 7, 3, 0]  \n",
       "1           [2, 17]  \n",
       "2        [3, 19, 6]  \n",
       "3   [12, 17, 19, 6]  \n",
       "4     [18, 3, 4, 1]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data=data_train.to_pandas()\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8b987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d031b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import shuffle\n",
    "LABEL_MAP=[0,1,2]  ##level 1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e865447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertForSequenceClassification\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "class Learner(nn.Module):\n",
    "    \"\"\"\n",
    "    Meta Learner\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Learner, self).__init__()\n",
    "        \n",
    "        self.num_labels = args.num_labels\n",
    "        self.outer_batch_size = args.outer_batch_size\n",
    "        self.inner_batch_size = args.inner_batch_size\n",
    "        self.outer_update_lr  = args.outer_update_lr\n",
    "        self.inner_update_lr  = args.inner_update_lr\n",
    "        self.inner_update_step = args.inner_update_step\n",
    "        self.inner_update_step_eval = args.inner_update_step_eval\n",
    "        self.bert_model = args.bert_model\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.model = BertForSequenceClassification.from_pretrained(self.bert_model, num_labels = self.num_labels)\n",
    "        self.outer_optimizer = Adam(self.model.parameters(), lr=self.outer_update_lr)\n",
    "        self.model.train()\n",
    "\n",
    "    def forward(self, batch_tasks, training = True):\n",
    "        \"\"\"\n",
    "        batch = [(support TensorDataset, query TensorDataset),\n",
    "                 (support TensorDataset, query TensorDataset),\n",
    "                 (support TensorDataset, query TensorDataset),\n",
    "                 (support TensorDataset, query TensorDataset)]\n",
    "        \n",
    "        # support = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, all_label_ids)\n",
    "        \"\"\"\n",
    "        task_accs = []\n",
    "        sum_gradients = []\n",
    "        num_task = len(batch_tasks)\n",
    "        num_inner_update_step = self.inner_update_step if training else self.inner_update_step_eval\n",
    "\n",
    "        for task_id, task in enumerate(batch_tasks):\n",
    "            support = task[0]\n",
    "            query   = task[1]\n",
    "            \n",
    "            fast_model = deepcopy(self.model)\n",
    "            fast_model.to(self.device)\n",
    "            support_dataloader = DataLoader(support, sampler=RandomSampler(support),\n",
    "                                            batch_size=self.inner_batch_size)\n",
    "            \n",
    "            inner_optimizer = Adam(fast_model.parameters(), lr=self.inner_update_lr)\n",
    "            fast_model.train()\n",
    "            \n",
    "            print('----Task',task_id, '----')\n",
    "            for i in range(0,num_inner_update_step):\n",
    "                all_loss = []\n",
    "                for inner_step, batch in enumerate(support_dataloader):\n",
    "                    \n",
    "                    batch = tuple(t.to(self.device) for t in batch)\n",
    "                    input_ids, attention_mask, segment_ids, label_id = batch\n",
    "                    outputs = fast_model(input_ids, attention_mask, segment_ids, labels = label_id)\n",
    "                    \n",
    "                    loss = outputs[0]              \n",
    "                    loss.backward()\n",
    "                    inner_optimizer.step()\n",
    "                    inner_optimizer.zero_grad()\n",
    "                    \n",
    "                    all_loss.append(loss.item())\n",
    "                \n",
    "                if i % 4 == 0:\n",
    "                    print(\"Inner Loss: \", np.mean(all_loss))\n",
    "\n",
    "            query_dataloader = DataLoader(query, sampler=None, batch_size=len(query))\n",
    "            query_batch = iter(query_dataloader).next()\n",
    "            query_batch = tuple(t.to(self.device) for t in query_batch)\n",
    "            q_input_ids, q_attention_mask, q_segment_ids, q_label_id = query_batch\n",
    "            q_outputs = fast_model(q_input_ids, q_attention_mask, q_segment_ids, labels = q_label_id)\n",
    "            \n",
    "            if training:\n",
    "                q_loss = q_outputs[0]\n",
    "                q_loss.backward()\n",
    "                fast_model.to(torch.device('cpu'))\n",
    "                for i, params in enumerate(fast_model.parameters()):\n",
    "                    if task_id == 0:\n",
    "                        sum_gradients.append(deepcopy(params.grad))\n",
    "                    else:\n",
    "                        sum_gradients[i] += deepcopy(params.grad)\n",
    "\n",
    "            q_logits = F.softmax(q_outputs[1],dim=1)\n",
    "            pre_label_id = torch.argmax(q_logits,dim=1)\n",
    "            pre_label_id = pre_label_id.detach().cpu().numpy().tolist()\n",
    "            q_label_id = q_label_id.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            acc = accuracy_score(pre_label_id,q_label_id)\n",
    "            conf= confusion_matrix(pre_label_id,q_label_id)\n",
    "            print(conf)\n",
    "            task_accs.append(acc)\n",
    "            \n",
    "            del fast_model, inner_optimizer\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        if training:\n",
    "            # Average gradient across tasks\n",
    "            for i in range(0,len(sum_gradients)):\n",
    "                sum_gradients[i] = sum_gradients[i] / float(num_task)\n",
    "\n",
    "            #Assign gradient for original model, then using optimizer to update its weights\n",
    "            for i, params in enumerate(self.model.parameters()):\n",
    "                params.grad = sum_gradients[i]\n",
    "\n",
    "            self.outer_optimizer.step()\n",
    "            self.outer_optimizer.zero_grad()\n",
    "            \n",
    "            del sum_gradients\n",
    "            gc.collect()\n",
    "        \n",
    "        return np.mean(task_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c46afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, random\n",
    "def random_seed(value):\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    np.random.seed(value)\n",
    "    random.seed(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0a3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_of_tasks(taskset, is_shuffle = True, batch_size = 4):\n",
    "    idxs = list(range(0,len(taskset)))\n",
    "    #idxs = list(range(0,512))\n",
    "    if is_shuffle:\n",
    "        random.shuffle(idxs)\n",
    "    for i in range(0,len(idxs), batch_size):\n",
    "        yield [taskset[idxs[i]] for i in range(i, min(i + batch_size,len(taskset)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "648a08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingArgs:\n",
    "    def __init__(self):\n",
    "        self.num_labels = 3\n",
    "        self.meta_epoch=10\n",
    "        self.k_spt=100\n",
    "        self.k_qry=30\n",
    "        self.outer_batch_size = 20    #\n",
    "        self.inner_batch_size = 50\n",
    "        self.outer_update_lr = 0.0005  #decrease\n",
    "        self.inner_update_lr = 0.0001\n",
    "        self.inner_update_step = 10\n",
    "        self.inner_update_step_eval = 40\n",
    "        self.bert_model = 'xlm-roberta-base'\n",
    "        self.num_task_train = 500\n",
    "        self.num_task_test = 5\n",
    "\n",
    "args = TrainingArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a361061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=de/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6/cache-36aa696a219cfefb.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=de/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6/cache-62e76f1ce8b8a142.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=de/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6/cache-9e4db2e8b6905f7f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9089\n"
     ]
    }
   ],
   "source": [
    "data_train_labels0 = data_train.filter(lambda x: (x[\"labels\"][0] == 0  ))\n",
    "data_train_labels1 = data_train.filter(lambda x: (x[\"labels\"][0] == 1  ))\n",
    "data_train_labels2 = data_train.filter(lambda x: (x[\"labels\"][0] == 2  ))\n",
    "\n",
    "print(len(data_train_labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2228dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=sk/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6/cache-cf007e649129a915.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=sk/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6/cache-b87557e9f39cd794.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c17a33d8a744acfbf9c46174ca2e3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "data_test_labels0 = data_test.filter(lambda x: (x[\"labels\"][0] == 0  ))\n",
    "data_test_labels1 = data_test.filter(lambda x: (x[\"labels\"][0] == 1  ))\n",
    "data_test_labels2 = data_test.filter(lambda x: (x[\"labels\"][0] == 2  ))\n",
    "\n",
    "print(len(data_test_labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "186ed3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=sk/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6/cache-568dbf313468cca4.arrow\n"
     ]
    }
   ],
   "source": [
    "test_examples_dataset1 = data_test_labels1.shuffle(seed=666).select(range(len(data_test_labels1)))\n",
    "test_examples_dataset0 = data_test_labels0.shuffle(seed=666).select(range(len(data_test_labels1)))\n",
    "test_examples_dataset2 = data_test_labels2.shuffle(seed=666).select(range(len(data_test_labels1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d19d113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data_train_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ead1fef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/multi_eurlex/default-language=de/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6/cache-ee2fb54945fda7d7.arrow\n"
     ]
    }
   ],
   "source": [
    "train_examples_dataset1 = data_train_labels1.shuffle(seed=666).select(range(len(data_train_labels1)))\n",
    "train_examples_dataset0 = data_train_labels0.shuffle(seed=666).select(range(len(data_train_labels1)))\n",
    "train_examples_dataset2 = data_train_labels2.shuffle(seed=666).select(range(len(data_train_labels1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "003ac6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "test_examples = []\n",
    "\n",
    "for i in range(len(train_examples_dataset1)):\n",
    "    train_examples.append(train_examples_dataset1[i])\n",
    "    train_examples.append(train_examples_dataset0[i])\n",
    "    train_examples.append(train_examples_dataset2[i])\n",
    "    \n",
    "        \n",
    "for i in range(len(test_examples_dataset1)):\n",
    "    test_examples.append(test_examples_dataset1[i])\n",
    "    test_examples.append(test_examples_dataset0[i])\n",
    "    test_examples.append(test_examples_dataset2[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c6577d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966 27267\n"
     ]
    }
   ],
   "source": [
    "print(len(test_examples),len(train_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "701a6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "class MetaTask(Dataset):\n",
    "    \n",
    "    def __init__(self, examples, num_task, k_support, k_query, tokenizer):\n",
    "        \"\"\"\n",
    "        :param samples: list of samples\n",
    "        :param num_task: number of training tasks.\n",
    "        :param k_support: number of support sample per task\n",
    "        :param k_query: number of query sample per task\n",
    "        \"\"\"\n",
    "        self.examples = examples\n",
    "        random.shuffle(self.examples)\n",
    "        \n",
    "        self.num_task = num_task\n",
    "        self.k_support = k_support\n",
    "        self.k_query = k_query\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = 128       #increase \n",
    "        self.create_batch(self.num_task)\n",
    "    \n",
    "    def create_batch(self, num_task):\n",
    "        self.supports = []  # support set\n",
    "        self.queries = []  # query set\n",
    "        \n",
    "        for b in range(num_task):  # for each task\n",
    "            # 1.select domain randomly\n",
    "            #domain = random.choice(self.examples)['domain']   #domain corresponds to low resource language\n",
    "            #domainExamples = [e for e in self.examples if e['domain'] == domain] \n",
    "            #domainExamples=random.choice(self.examples)\n",
    "            domainExamples=random.sample(self.examples,200)\n",
    "            # 1.select k_support + k_query examples from domain randomly\n",
    "            selected_examples = random.sample(list(domainExamples),self.k_support + self.k_query)\n",
    "            random.shuffle(selected_examples)\n",
    "            exam_train = selected_examples[:self.k_support]\n",
    "            exam_test  = selected_examples[self.k_support:]\n",
    "            \n",
    "            self.supports.append(exam_train)\n",
    "            self.queries.append(exam_test)\n",
    "\n",
    "    def create_feature_set(self,examples):\n",
    "        all_input_ids      = torch.empty((len(examples), self.max_seq_length), dtype = torch.long)\n",
    "        all_attention_mask = torch.empty((len(examples), self.max_seq_length), dtype = torch.long)\n",
    "        all_segment_ids    = torch.empty((len(examples), self.max_seq_length), dtype = torch.long)\n",
    "        all_label_ids      = torch.empty(len(examples), dtype = torch.long)\n",
    "\n",
    "        for id_,example in enumerate(examples):\n",
    "            input_ids = tokenizer.encode(example['text'][:self.max_seq_length])\n",
    "            attention_mask = [1] * len(input_ids)\n",
    "            segment_ids    = [0] * len(input_ids)\n",
    "\n",
    "            while len(input_ids) < self.max_seq_length:\n",
    "            #while len(input_ids) < len(example['text']):\n",
    "                input_ids.append(0)\n",
    "                attention_mask.append(0)\n",
    "                segment_ids.append(0)\n",
    "\n",
    "            #label_id = LABEL_MAP[example['label']].  ##check labels\n",
    "            label_id = LABEL_MAP[example['labels'][0]]\n",
    "            all_input_ids[id_] = torch.Tensor(input_ids).to(torch.long)\n",
    "            all_attention_mask[id_] = torch.Tensor(attention_mask).to(torch.long)\n",
    "            all_segment_ids[id_] = torch.Tensor(segment_ids).to(torch.long)\n",
    "            all_label_ids[id_] = torch.Tensor([label_id]).to(torch.long)\n",
    "\n",
    "        tensor_set = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, all_label_ids)  \n",
    "        return tensor_set\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        support_set = self.create_feature_set(self.supports[index])\n",
    "        query_set   = self.create_feature_set(self.queries[index])\n",
    "        return support_set, query_set\n",
    "\n",
    "    def __len__(self):\n",
    "        # as we have built up to batchsz of sets, you can sample some small batch size of sets.\n",
    "        return self.num_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "745fe7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.TensorDataset at 0x7f41277fdf50>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x7f4124147f90>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base', do_lower_case = True)\n",
    "train = MetaTask(train_examples, num_task = 100, k_support=100, k_query=30, tokenizer = tokenizer)\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7bc15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.5.output.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'lm_head.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.1.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['embeddings.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'classifier.weight', 'encoder.layer.5.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Task 0 ----\n",
      "Inner Loss:  1.967118501663208\n",
      "Inner Loss:  1.1413964629173279\n",
      "Inner Loss:  1.1446737051010132\n",
      "[[ 1  2  1]\n",
      " [ 0  0  0]\n",
      " [11  5 10]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  1.6517819166183472\n",
      "Inner Loss:  1.1064550280570984\n",
      "Inner Loss:  1.1046413779258728\n",
      "[[ 0  0  0]\n",
      " [13 11  6]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  1.3573737740516663\n",
      "Inner Loss:  1.094359576702118\n",
      "Inner Loss:  1.0915486216545105\n",
      "[[0 0 0]\n",
      " [7 5 6]\n",
      " [4 5 3]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  1.66815584897995\n",
      "Inner Loss:  1.1100044250488281\n",
      "Inner Loss:  1.0742945075035095\n",
      "[[ 0  0  0]\n",
      " [ 1  0  3]\n",
      " [10  8  8]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  2.0182148814201355\n",
      "Inner Loss:  1.1265615820884705\n",
      "Inner Loss:  1.10004460811615\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [ 5 12 12]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  2.113706350326538\n",
      "Inner Loss:  1.117698609828949\n",
      "Inner Loss:  1.1131379008293152\n",
      "[[ 1  0  0]\n",
      " [ 0  0  0]\n",
      " [14  9  6]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  1.2059524655342102\n",
      "Inner Loss:  1.1052802205085754\n",
      "Inner Loss:  1.1209802031517029\n",
      "[[8 7 5]\n",
      " [2 1 4]\n",
      " [2 1 0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  1.2418462038040161\n",
      "Inner Loss:  1.0929328799247742\n",
      "Inner Loss:  1.0898998379707336\n",
      "[[ 6 15  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  1.9182963371276855\n",
      "Inner Loss:  1.1128499507904053\n",
      "Inner Loss:  1.1108330488204956\n",
      "[[7 5 5]\n",
      " [5 2 6]\n",
      " [0 0 0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  1.7342856526374817\n",
      "Inner Loss:  1.116058111190796\n",
      "Inner Loss:  1.1252381801605225\n",
      "[[10 10  5]\n",
      " [ 2  0  3]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  2.3537052273750305\n",
      "Inner Loss:  1.1214593648910522\n",
      "Inner Loss:  1.106954038143158\n",
      "[[4 5 3]\n",
      " [5 4 9]\n",
      " [0 0 0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  2.1860654950141907\n",
      "Inner Loss:  1.162290871143341\n",
      "Inner Loss:  1.1181485056877136\n",
      "[[9 6 9]\n",
      " [1 2 2]\n",
      " [0 1 0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  1.1985633373260498\n",
      "Inner Loss:  1.1667729020118713\n",
      "Inner Loss:  1.0903717875480652\n",
      "[[ 3  1  3]\n",
      " [ 4  9 10]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  1.627256453037262\n",
      "Inner Loss:  1.1406518816947937\n",
      "Inner Loss:  1.0928541421890259\n",
      "[[9 7 5]\n",
      " [0 0 0]\n",
      " [4 3 2]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  1.5635854005813599\n",
      "Inner Loss:  1.1330264806747437\n",
      "Inner Loss:  1.1250017881393433\n",
      "[[ 0  0  0]\n",
      " [ 2  1  1]\n",
      " [ 7 11  8]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  1.2889167070388794\n",
      "Inner Loss:  1.112006425857544\n",
      "Inner Loss:  1.0976852774620056\n",
      "[[ 0  0  0]\n",
      " [ 9 12  9]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  1.8422369956970215\n",
      "Inner Loss:  1.1313136219978333\n",
      "Inner Loss:  1.1107781529426575\n",
      "[[ 7 12  8]\n",
      " [ 0  0  0]\n",
      " [ 0  3  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  2.4897645711898804\n",
      "Inner Loss:  1.1340745687484741\n",
      "Inner Loss:  1.1100980639457703\n",
      "[[ 0  1  2]\n",
      " [ 8  9 10]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  1.7639675736427307\n",
      "Inner Loss:  1.1197106838226318\n",
      "Inner Loss:  1.099421739578247\n",
      "[[0 0 0]\n",
      " [7 6 8]\n",
      " [0 3 6]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  2.1683221459388733\n",
      "Inner Loss:  1.1377511024475098\n",
      "Inner Loss:  1.118420422077179\n",
      "[[11 11  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "Step: 0 \ttraining Acc: 0.32333333333333336\n",
      "\n",
      "-----------------Testing Mode-----------------\n",
      "\n",
      "----Task 0 ----\n",
      "Inner Loss:  2.0962007641792297\n",
      "Inner Loss:  1.1321620345115662\n",
      "Inner Loss:  1.109659194946289\n",
      "Inner Loss:  1.0762719511985779\n",
      "Inner Loss:  1.0953114032745361\n",
      "Inner Loss:  1.090539276599884\n",
      "Inner Loss:  1.0811505317687988\n",
      "Inner Loss:  1.1006418466567993\n",
      "Inner Loss:  1.0958381295204163\n",
      "Inner Loss:  1.0770792365074158\n",
      "[[ 5 10 14]\n",
      " [ 0  0  0]\n",
      " [ 1  0  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  1.6269899010658264\n",
      "Inner Loss:  1.1269494891166687\n",
      "Inner Loss:  1.10234534740448\n",
      "Inner Loss:  1.1005693078041077\n",
      "Inner Loss:  1.0988213419914246\n",
      "Inner Loss:  1.1091638803482056\n",
      "Inner Loss:  1.1050063967704773\n",
      "Inner Loss:  1.083493411540985\n",
      "Inner Loss:  1.1021868586540222\n",
      "Inner Loss:  1.1274932026863098\n",
      "[[ 5  6 10]\n",
      " [ 2  2  4]\n",
      " [ 0  0  1]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  1.6716594696044922\n",
      "Inner Loss:  1.1267055869102478\n",
      "Inner Loss:  1.0958039164543152\n",
      "Inner Loss:  1.1022188663482666\n",
      "Inner Loss:  1.08034086227417\n",
      "Inner Loss:  1.1001983284950256\n",
      "Inner Loss:  1.083120048046112\n",
      "Inner Loss:  1.077580988407135\n",
      "Inner Loss:  1.0982902646064758\n",
      "Inner Loss:  1.0937873125076294\n",
      "[[ 0  0  0]\n",
      " [ 9 10 10]\n",
      " [ 0  1  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  1.716965675354004\n",
      "Inner Loss:  1.145113229751587\n",
      "Inner Loss:  1.1074200868606567\n",
      "Inner Loss:  1.0903156995773315\n",
      "Inner Loss:  1.1124245524406433\n",
      "Inner Loss:  1.092523992061615\n",
      "Inner Loss:  1.086981475353241\n",
      "Inner Loss:  1.0841463804244995\n",
      "Inner Loss:  1.1102401614189148\n",
      "Inner Loss:  1.098326563835144\n",
      "[[ 1  1  0]\n",
      " [ 6 13  9]\n",
      " [ 0  0  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  1.9533140063285828\n",
      "Inner Loss:  1.1414017081260681\n",
      "Inner Loss:  1.1124439239501953\n",
      "Inner Loss:  1.1278297305107117\n",
      "Inner Loss:  1.095930576324463\n",
      "Inner Loss:  1.1189278960227966\n",
      "Inner Loss:  1.1021698117256165\n",
      "Inner Loss:  1.082410991191864\n",
      "Inner Loss:  1.112463891506195\n",
      "Inner Loss:  1.100544273853302\n",
      "[[4 3 0]\n",
      " [5 4 7]\n",
      " [3 1 3]]\n",
      "Step: 0 Test F1: 0.32\n",
      "----Task 0 ----\n",
      "Inner Loss:  1.839497983455658\n",
      "Inner Loss:  1.1084697246551514\n",
      "Inner Loss:  1.0929075479507446\n",
      "[[ 1  4  0]\n",
      " [ 0  0  0]\n",
      " [ 9  6 10]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  1.8248799443244934\n",
      "Inner Loss:  1.111321210861206\n",
      "Inner Loss:  1.111502468585968\n",
      "[[ 2 14  6]\n",
      " [ 1  3  1]\n",
      " [ 0  1  2]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  1.9472606778144836\n",
      "Inner Loss:  1.1144840717315674\n",
      "Inner Loss:  1.087998867034912\n",
      "[[7 5 7]\n",
      " [0 0 0]\n",
      " [6 2 3]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  2.3052788972854614\n",
      "Inner Loss:  1.1377676129341125\n",
      "Inner Loss:  1.1045451164245605\n",
      "[[15  9  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  1.8555803894996643\n",
      "Inner Loss:  1.153406798839569\n",
      "Inner Loss:  1.106801688671112\n",
      "[[15  7  7]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  1.813718855381012\n",
      "Inner Loss:  1.1479256749153137\n",
      "Inner Loss:  1.113735318183899\n",
      "[[11  9 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  1.781014084815979\n",
      "Inner Loss:  1.1417816877365112\n",
      "Inner Loss:  1.118950366973877\n",
      "[[2 1 2]\n",
      " [6 3 2]\n",
      " [8 3 3]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  1.9485810995101929\n",
      "Inner Loss:  1.1412709951400757\n",
      "Inner Loss:  1.130119502544403\n",
      "[[5 4 2]\n",
      " [8 6 5]\n",
      " [0 0 0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  1.7821142673492432\n",
      "Inner Loss:  1.1216004490852356\n",
      "Inner Loss:  1.1230663657188416\n",
      "[[ 7 10 10]\n",
      " [ 0  1  1]\n",
      " [ 0  0  1]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  1.9768708944320679\n",
      "Inner Loss:  1.153157353401184\n",
      "Inner Loss:  1.1108885407447815\n",
      "[[4 3 2]\n",
      " [4 8 9]\n",
      " [0 0 0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  1.7009257674217224\n",
      "Inner Loss:  1.1265480518341064\n",
      "Inner Loss:  1.1110881567001343\n",
      "[[4 3 2]\n",
      " [4 8 8]\n",
      " [0 1 0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  1.6739962697029114\n",
      "Inner Loss:  1.144052803516388\n",
      "Inner Loss:  1.1182007789611816\n",
      "[[3 9 3]\n",
      " [0 1 0]\n",
      " [8 2 4]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  1.8663323521614075\n",
      "Inner Loss:  1.1429980397224426\n",
      "Inner Loss:  1.1197292804718018\n",
      "[[ 8  7 12]\n",
      " [ 0  0  0]\n",
      " [ 2  0  1]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  1.904415488243103\n",
      "Inner Loss:  1.1211156845092773\n",
      "Inner Loss:  1.1390528082847595\n",
      "[[ 5  5 10]\n",
      " [ 2  5  3]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  1.9070892333984375\n",
      "Inner Loss:  1.1265531182289124\n",
      "Inner Loss:  1.0988529324531555\n",
      "[[6 7 7]\n",
      " [4 4 2]\n",
      " [0 0 0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  1.9328383207321167\n",
      "Inner Loss:  1.1063457131385803\n",
      "Inner Loss:  1.0963550209999084\n",
      "[[ 3 13 14]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  1.9710467457771301\n",
      "Inner Loss:  1.127506971359253\n",
      "Inner Loss:  1.1236060857772827\n",
      "[[1 7 1]\n",
      " [6 6 9]\n",
      " [0 0 0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  1.8372177481651306\n",
      "Inner Loss:  1.0926935076713562\n",
      "Inner Loss:  1.0933501720428467\n",
      "[[ 6 13  3]\n",
      " [ 3  3  2]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  1.8417268991470337\n",
      "Inner Loss:  1.1501951813697815\n",
      "Inner Loss:  1.1169601082801819\n",
      "[[ 7 10  6]\n",
      " [ 2  3  2]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  1.8178097605705261\n",
      "Inner Loss:  1.1249004006385803\n",
      "Inner Loss:  1.1312046647071838\n",
      "[[6 5 5]\n",
      " [1 1 1]\n",
      " [4 2 5]]\n",
      "Step: 1 \ttraining Acc: 0.33166666666666667\n",
      "----Task 0 ----\n",
      "Inner Loss:  1.6708480715751648\n",
      "Inner Loss:  1.1101267337799072\n",
      "Inner Loss:  1.0958473086357117\n",
      "[[8 6 3]\n",
      " [4 3 6]\n",
      " [0 0 0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  1.5981720685958862\n",
      "Inner Loss:  1.256913423538208\n",
      "Inner Loss:  1.107107698917389\n",
      "[[ 0  0  0]\n",
      " [12  7 11]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  1.6275390982627869\n",
      "Inner Loss:  1.3324203491210938\n",
      "Inner Loss:  1.1498013734817505\n",
      "[[ 0  0  0]\n",
      " [10 11  9]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  1.6923490166664124\n",
      "Inner Loss:  1.147075891494751\n",
      "Inner Loss:  1.128090739250183\n",
      "[[7 5 6]\n",
      " [2 7 3]\n",
      " [0 0 0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  1.3474668264389038\n",
      "Inner Loss:  1.1109622716903687\n",
      "Inner Loss:  1.1330409049987793\n",
      "[[5 7 5]\n",
      " [7 2 4]\n",
      " [0 0 0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  1.686195194721222\n",
      "Inner Loss:  1.1871368288993835\n",
      "Inner Loss:  1.1317747235298157\n",
      "[[ 3  3  1]\n",
      " [ 6  6 11]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  1.6181167364120483\n",
      "Inner Loss:  1.2725419402122498\n",
      "Inner Loss:  1.1192482709884644\n",
      "[[3 3 4]\n",
      " [5 5 5]\n",
      " [3 0 2]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  1.5187709331512451\n",
      "Inner Loss:  1.2404873371124268\n",
      "Inner Loss:  1.1307526230812073\n",
      "[[ 2  0  2]\n",
      " [ 6 13  7]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  1.7246458530426025\n",
      "Inner Loss:  1.2687017917633057\n",
      "Inner Loss:  1.1199890971183777\n",
      "[[7 2 1]\n",
      " [5 4 9]\n",
      " [0 0 2]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  1.5987796783447266\n",
      "Inner Loss:  1.2255183458328247\n",
      "Inner Loss:  1.1280253529548645\n",
      "[[9 5 5]\n",
      " [2 5 4]\n",
      " [0 0 0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  1.4996173977851868\n",
      "Inner Loss:  1.194636046886444\n",
      "Inner Loss:  1.1502819061279297\n",
      "[[4 7 6]\n",
      " [6 4 3]\n",
      " [0 0 0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  1.3645157217979431\n",
      "Inner Loss:  1.1829712986946106\n",
      "Inner Loss:  1.1090929508209229\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 11 10]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  1.5543038845062256\n",
      "Inner Loss:  1.1981098651885986\n",
      "Inner Loss:  1.1461079716682434\n",
      "[[10  9  8]\n",
      " [ 1  1  1]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  1.6185953617095947\n",
      "Inner Loss:  1.1958752274513245\n",
      "Inner Loss:  1.1359256505966187\n",
      "[[2 3 7]\n",
      " [6 7 5]\n",
      " [0 0 0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  1.708690345287323\n",
      "Inner Loss:  1.243657410144806\n",
      "Inner Loss:  1.1103903651237488\n",
      "[[ 0  0  0]\n",
      " [10  9 11]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  1.8544793725013733\n",
      "Inner Loss:  1.1408493518829346\n",
      "Inner Loss:  1.0848345756530762\n",
      "[[ 0  0  0]\n",
      " [11 10  9]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  1.5883397459983826\n",
      "Inner Loss:  1.1456041932106018\n",
      "Inner Loss:  1.109306812286377\n",
      "[[0 0 0]\n",
      " [4 5 4]\n",
      " [7 5 5]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  1.44064199924469\n",
      "Inner Loss:  1.2569993734359741\n",
      "Inner Loss:  1.1300085186958313\n",
      "[[ 0  0  0]\n",
      " [10  6  8]\n",
      " [ 2  1  3]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  1.6760162711143494\n",
      "Inner Loss:  1.3141806721687317\n",
      "Inner Loss:  1.078895926475525\n",
      "[[4 4 3]\n",
      " [8 6 5]\n",
      " [0 0 0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  1.4547129273414612\n",
      "Inner Loss:  1.3043746948242188\n",
      "Inner Loss:  1.1532258987426758\n",
      "[[ 0  0  0]\n",
      " [ 7  5 13]\n",
      " [ 4  1  0]]\n",
      "Step: 2 \ttraining Acc: 0.3366666666666666\n",
      "----Task 0 ----\n",
      "Inner Loss:  2.124593138694763\n",
      "Inner Loss:  1.312318503856659\n",
      "Inner Loss:  1.166358232498169\n",
      "[[ 7 10 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  2.7434029579162598\n",
      "Inner Loss:  1.3081372380256653\n",
      "Inner Loss:  1.1272988319396973\n",
      "[[ 9  8 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  2.466110944747925\n",
      "Inner Loss:  1.2077161073684692\n",
      "Inner Loss:  1.142570972442627\n",
      "[[ 0  0  0]\n",
      " [ 1  2  0]\n",
      " [13  4 10]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  2.33462393283844\n",
      "Inner Loss:  1.4990355372428894\n",
      "Inner Loss:  1.1780543327331543\n",
      "[[ 0  0  0]\n",
      " [10 11  9]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  2.350870728492737\n",
      "Inner Loss:  1.1715982556343079\n",
      "Inner Loss:  1.1222680807113647\n",
      "[[ 0  0  0]\n",
      " [ 8 12 10]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  2.375060200691223\n",
      "Inner Loss:  1.2603281736373901\n",
      "Inner Loss:  1.1245086193084717\n",
      "[[ 7 11 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  2.4358080625534058\n",
      "Inner Loss:  1.7371925711631775\n",
      "Inner Loss:  1.1989156007766724\n",
      "[[ 0  0  0]\n",
      " [12  5 13]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  2.244394063949585\n",
      "Inner Loss:  1.2621012330055237\n",
      "Inner Loss:  1.1155081391334534\n",
      "[[ 0  0  0]\n",
      " [14  7  7]\n",
      " [ 0  1  1]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  2.2742574214935303\n",
      "Inner Loss:  1.2800071835517883\n",
      "Inner Loss:  1.168186902999878\n",
      "[[ 7 10 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  2.1476919651031494\n",
      "Inner Loss:  1.2748135328292847\n",
      "Inner Loss:  1.123820424079895\n",
      "[[0 0 0]\n",
      " [3 4 4]\n",
      " [7 8 4]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  1.9293888807296753\n",
      "Inner Loss:  1.2991047501564026\n",
      "Inner Loss:  1.119832694530487\n",
      "[[ 0  0  0]\n",
      " [ 8 15  7]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  2.4146084785461426\n",
      "Inner Loss:  1.4886042475700378\n",
      "Inner Loss:  1.1832815408706665\n",
      "[[ 0  0  0]\n",
      " [ 7 15  8]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  2.321388840675354\n",
      "Inner Loss:  1.2176964282989502\n",
      "Inner Loss:  1.1336746215820312\n",
      "[[ 3 10 13]\n",
      " [ 2  2  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  2.687339663505554\n",
      "Inner Loss:  1.3922597765922546\n",
      "Inner Loss:  1.1850808262825012\n",
      "[[ 0  0  0]\n",
      " [10 14  6]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  2.4757381677627563\n",
      "Inner Loss:  1.6153266429901123\n",
      "Inner Loss:  1.1949823498725891\n",
      "[[ 0  0  0]\n",
      " [10 16  4]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  2.374508857727051\n",
      "Inner Loss:  1.2796657085418701\n",
      "Inner Loss:  1.198814570903778\n",
      "[[ 0  0  0]\n",
      " [ 8 12 10]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  1.9143128991127014\n",
      "Inner Loss:  1.442258894443512\n",
      "Inner Loss:  1.124699592590332\n",
      "[[ 0  0  0]\n",
      " [ 9 11 10]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  1.7998430132865906\n",
      "Inner Loss:  1.1229025721549988\n",
      "Inner Loss:  1.0783410668373108\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10  9 11]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  2.163365960121155\n",
      "Inner Loss:  1.49032461643219\n",
      "Inner Loss:  1.1300981640815735\n",
      "[[0 0 0]\n",
      " [5 1 7]\n",
      " [6 7 4]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  2.0591458678245544\n",
      "Inner Loss:  1.2038540840148926\n",
      "Inner Loss:  1.0847722887992859\n",
      "[[10 11  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "Step: 3 \ttraining Acc: 0.3333333333333333\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.1083126068115234\n",
      "Inner Loss:  1.1952389478683472\n",
      "Inner Loss:  1.0977649688720703\n",
      "[[ 0  0  1]\n",
      " [ 8 10 11]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.486452102661133\n",
      "Inner Loss:  1.3225455284118652\n",
      "Inner Loss:  1.171532928943634\n",
      "[[11  7 11]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.015827298164368\n",
      "Inner Loss:  1.2621724009513855\n",
      "Inner Loss:  1.132332444190979\n",
      "[[3 5 3]\n",
      " [0 0 0]\n",
      " [5 5 9]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.3342556953430176\n",
      "Inner Loss:  1.3312972784042358\n",
      "Inner Loss:  1.1764427423477173\n",
      "[[6 3 7]\n",
      " [6 3 5]\n",
      " [0 0 0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.6045870780944824\n",
      "Inner Loss:  1.417212963104248\n",
      "Inner Loss:  1.1692814826965332\n",
      "[[ 0  0  0]\n",
      " [10 10 10]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.3205097913742065\n",
      "Inner Loss:  1.3573249578475952\n",
      "Inner Loss:  1.168630838394165\n",
      "[[9 5 6]\n",
      " [3 2 3]\n",
      " [0 2 0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.3868218660354614\n",
      "Inner Loss:  1.247330367565155\n",
      "Inner Loss:  1.138746201992035\n",
      "[[12  7  8]\n",
      " [ 0  1  1]\n",
      " [ 0  1  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.403116822242737\n",
      "Inner Loss:  1.2739439606666565\n",
      "Inner Loss:  1.141458511352539\n",
      "[[11  8 10]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.5750999450683594\n",
      "Inner Loss:  1.2196719646453857\n",
      "Inner Loss:  1.140404760837555\n",
      "[[4 4 3]\n",
      " [6 4 7]\n",
      " [2 0 0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.510089635848999\n",
      "Inner Loss:  1.36258465051651\n",
      "Inner Loss:  1.1710699796676636\n",
      "[[0 0 0]\n",
      " [6 3 8]\n",
      " [5 3 5]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.8407176733016968\n",
      "Inner Loss:  1.216568112373352\n",
      "Inner Loss:  1.1336222290992737\n",
      "[[ 7  7 12]\n",
      " [ 0  0  0]\n",
      " [ 1  3  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.247838854789734\n",
      "Inner Loss:  1.3684051632881165\n",
      "Inner Loss:  1.1685381531715393\n",
      "[[ 7 10  4]\n",
      " [ 6  2  1]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.3692210912704468\n",
      "Inner Loss:  1.4328583478927612\n",
      "Inner Loss:  1.1077662110328674\n",
      "[[ 0  1  0]\n",
      " [11 13  5]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  3.196648597717285\n",
      "Inner Loss:  1.112962782382965\n",
      "Inner Loss:  1.1109171509742737\n",
      "[[ 0  0  0]\n",
      " [ 2  3  4]\n",
      " [ 4 11  6]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.5882203578948975\n",
      "Inner Loss:  1.4634341597557068\n",
      "Inner Loss:  1.157059371471405\n",
      "[[ 0  0  0]\n",
      " [10 10 10]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.762089490890503\n",
      "Inner Loss:  1.173660695552826\n",
      "Inner Loss:  1.1059201955795288\n",
      "[[4 3 1]\n",
      " [0 0 0]\n",
      " [6 8 8]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.751869797706604\n",
      "Inner Loss:  1.2601341009140015\n",
      "Inner Loss:  1.134209930896759\n",
      "[[12  6  8]\n",
      " [ 0  1  1]\n",
      " [ 0  2  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.473961114883423\n",
      "Inner Loss:  1.3240193724632263\n",
      "Inner Loss:  1.1585107445716858\n",
      "[[8 7 4]\n",
      " [5 4 2]\n",
      " [0 0 0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.7137540578842163\n",
      "Inner Loss:  1.474514901638031\n",
      "Inner Loss:  1.1200652122497559\n",
      "[[ 0  0  0]\n",
      " [10 10  9]\n",
      " [ 1  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.727281093597412\n",
      "Inner Loss:  1.1354911923408508\n",
      "Inner Loss:  1.108827531337738\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 12 11]]\n",
      "Step: 4 \ttraining Acc: 0.35\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.970955967903137\n",
      "Inner Loss:  1.2034833431243896\n",
      "Inner Loss:  1.1413110494613647\n",
      "[[ 1  1  0]\n",
      " [ 1  0  0]\n",
      " [10  7 10]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.6756067276000977\n",
      "Inner Loss:  1.2098183035850525\n",
      "Inner Loss:  1.1095541715621948\n",
      "[[6 1 1]\n",
      " [1 3 3]\n",
      " [7 4 4]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.7827231884002686\n",
      "Inner Loss:  1.2689537405967712\n",
      "Inner Loss:  1.1742377281188965\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [15  3 12]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.117888450622559\n",
      "Inner Loss:  1.2955458164215088\n",
      "Inner Loss:  1.168655514717102\n",
      "[[ 1  1  0]\n",
      " [ 0  0  1]\n",
      " [ 8  8 11]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.871799349784851\n",
      "Inner Loss:  1.157573938369751\n",
      "Inner Loss:  1.1096860766410828\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13  9  8]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.9812413454055786\n",
      "Inner Loss:  1.2565553784370422\n",
      "Inner Loss:  1.1569932699203491\n",
      "[[3 4 5]\n",
      " [1 3 3]\n",
      " [4 6 1]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.9342206716537476\n",
      "Inner Loss:  1.2544044852256775\n",
      "Inner Loss:  1.14364755153656\n",
      "[[ 2  2  1]\n",
      " [ 0  0  0]\n",
      " [ 6 10  9]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.938807249069214\n",
      "Inner Loss:  1.3095605969429016\n",
      "Inner Loss:  1.1621827483177185\n",
      "[[ 0  1  0]\n",
      " [ 0  1  0]\n",
      " [11  8  9]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.7297762632369995\n",
      "Inner Loss:  1.1937823295593262\n",
      "Inner Loss:  1.1202390789985657\n",
      "[[ 0  0  0]\n",
      " [10 10 10]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.59596848487854\n",
      "Inner Loss:  1.2842941880226135\n",
      "Inner Loss:  1.1759227514266968\n",
      "[[ 0  0  0]\n",
      " [ 1  1  2]\n",
      " [10  5 11]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.5660197734832764\n",
      "Inner Loss:  1.1624417901039124\n",
      "Inner Loss:  1.1115854978561401\n",
      "[[10  9 10]\n",
      " [ 0  0  0]\n",
      " [ 0  1  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.024780631065369\n",
      "Inner Loss:  1.2231966257095337\n",
      "Inner Loss:  1.1413549780845642\n",
      "[[ 1  0  0]\n",
      " [ 0  0  0]\n",
      " [ 5 12 12]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.9671590328216553\n",
      "Inner Loss:  1.1448246836662292\n",
      "Inner Loss:  1.1150058507919312\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8  9 13]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.717321991920471\n",
      "Inner Loss:  1.3062845468521118\n",
      "Inner Loss:  1.170009195804596\n",
      "[[12  9  8]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.9620656967163086\n",
      "Inner Loss:  1.2638908624649048\n",
      "Inner Loss:  1.1471635103225708\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9  7 14]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.3132652044296265\n",
      "Inner Loss:  1.2105740904808044\n",
      "Inner Loss:  1.156407356262207\n",
      "[[4 2 3]\n",
      " [7 7 6]\n",
      " [0 0 1]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.531723976135254\n",
      "Inner Loss:  1.1917827129364014\n",
      "Inner Loss:  1.1340954303741455\n",
      "[[9 8 3]\n",
      " [0 1 3]\n",
      " [2 0 4]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.806980013847351\n",
      "Inner Loss:  1.2771698832511902\n",
      "Inner Loss:  1.1699553728103638\n",
      "[[0 0 0]\n",
      " [3 3 2]\n",
      " [8 8 6]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.975083827972412\n",
      "Inner Loss:  1.229275405406952\n",
      "Inner Loss:  1.1155654788017273\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 11 10]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.7758995294570923\n",
      "Inner Loss:  1.2882710695266724\n",
      "Inner Loss:  1.159110188484192\n",
      "[[ 0  0  0]\n",
      " [12  9  8]\n",
      " [ 0  0  1]]\n",
      "Step: 5 \ttraining Acc: 0.37166666666666665\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.123667240142822\n",
      "Inner Loss:  1.2104782462120056\n",
      "Inner Loss:  1.1556711196899414\n",
      "[[ 1  0  0]\n",
      " [ 0  0  0]\n",
      " [10  9 10]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.235867619514465\n",
      "Inner Loss:  1.1721318364143372\n",
      "Inner Loss:  1.088638424873352\n",
      "[[12 10  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.341953754425049\n",
      "Inner Loss:  1.253038227558136\n",
      "Inner Loss:  1.1251755356788635\n",
      "[[ 8 11 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.602313876152039\n",
      "Inner Loss:  1.217638373374939\n",
      "Inner Loss:  1.1287692785263062\n",
      "[[ 0  0  0]\n",
      " [ 1  0  0]\n",
      " [ 9 10 10]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.498450756072998\n",
      "Inner Loss:  1.2246581315994263\n",
      "Inner Loss:  1.1291263103485107\n",
      "[[ 0  0  0]\n",
      " [ 1  1  0]\n",
      " [ 8 13  7]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.064384698867798\n",
      "Inner Loss:  1.1428245902061462\n",
      "Inner Loss:  1.1188828945159912\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [12  9  8]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.857198715209961\n",
      "Inner Loss:  1.1947652101516724\n",
      "Inner Loss:  1.1603979468345642\n",
      "[[ 0  0  0]\n",
      " [10  8  8]\n",
      " [ 3  1  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.1855690479278564\n",
      "Inner Loss:  1.2017925381660461\n",
      "Inner Loss:  1.0948790311813354\n",
      "[[14  9  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.120680570602417\n",
      "Inner Loss:  1.245339035987854\n",
      "Inner Loss:  1.1565639972686768\n",
      "[[ 0  1  1]\n",
      " [ 2  1  1]\n",
      " [11  5  8]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.753061771392822\n",
      "Inner Loss:  1.244317889213562\n",
      "Inner Loss:  1.156664490699768\n",
      "[[ 0  0  0]\n",
      " [ 1  0  1]\n",
      " [12  7  9]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.192587614059448\n",
      "Inner Loss:  1.2401037216186523\n",
      "Inner Loss:  1.152570366859436\n",
      "[[4 4 6]\n",
      " [2 6 0]\n",
      " [3 3 2]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.8731123208999634\n",
      "Inner Loss:  1.222573697566986\n",
      "Inner Loss:  1.1207494735717773\n",
      "[[1 6 2]\n",
      " [0 0 0]\n",
      " [7 6 8]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.489655256271362\n",
      "Inner Loss:  1.2277911305427551\n",
      "Inner Loss:  1.1566792726516724\n",
      "[[ 0  0  0]\n",
      " [ 0  1  2]\n",
      " [11 12  4]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.821748614311218\n",
      "Inner Loss:  1.2568023800849915\n",
      "Inner Loss:  1.1619204878807068\n",
      "[[ 0  0  0]\n",
      " [14  7  9]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.187777519226074\n",
      "Inner Loss:  1.1481106877326965\n",
      "Inner Loss:  1.1177138090133667\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13  8  9]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.496685981750488\n",
      "Inner Loss:  1.1614065170288086\n",
      "Inner Loss:  1.1407185792922974\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 11 12]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.036518812179565\n",
      "Inner Loss:  1.2211308479309082\n",
      "Inner Loss:  1.1465458273887634\n",
      "[[3 3 2]\n",
      " [0 0 0]\n",
      " [9 7 6]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.719167947769165\n",
      "Inner Loss:  1.18240624666214\n",
      "Inner Loss:  1.1270450949668884\n",
      "[[ 0  0  0]\n",
      " [ 1  2  2]\n",
      " [10  9  6]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.5377713441848755\n",
      "Inner Loss:  1.1412350535392761\n",
      "Inner Loss:  1.1055837273597717\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 12  7]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.423439025878906\n",
      "Inner Loss:  1.2273246049880981\n",
      "Inner Loss:  1.1358509063720703\n",
      "[[0 0 0]\n",
      " [7 3 9]\n",
      " [5 1 5]]\n",
      "Step: 6 \ttraining Acc: 0.30666666666666664\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.183697581291199\n",
      "Inner Loss:  1.861964762210846\n",
      "Inner Loss:  1.089685320854187\n",
      "[[6 6 6]\n",
      " [0 0 0]\n",
      " [2 3 7]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.2745858430862427\n",
      "Inner Loss:  2.3614776134490967\n",
      "Inner Loss:  1.1639444828033447\n",
      "[[11  9  6]\n",
      " [ 0  0  0]\n",
      " [ 2  2  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.890902042388916\n",
      "Inner Loss:  1.7102322578430176\n",
      "Inner Loss:  1.0913607478141785\n",
      "[[10  9 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.679816961288452\n",
      "Inner Loss:  1.4020956158638\n",
      "Inner Loss:  1.1277190446853638\n",
      "[[10  6 14]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.4830678701400757\n",
      "Inner Loss:  2.2142629623413086\n",
      "Inner Loss:  1.14512437582016\n",
      "[[ 8 13  6]\n",
      " [ 0  0  0]\n",
      " [ 2  1  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.8606770038604736\n",
      "Inner Loss:  2.524535894393921\n",
      "Inner Loss:  1.1645694971084595\n",
      "[[ 8 10  3]\n",
      " [ 0  0  0]\n",
      " [ 5  2  2]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.7214903831481934\n",
      "Inner Loss:  2.308727502822876\n",
      "Inner Loss:  1.122018814086914\n",
      "[[ 5 14  6]\n",
      " [ 0  0  0]\n",
      " [ 2  1  2]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.524982929229736\n",
      "Inner Loss:  1.1741161346435547\n",
      "Inner Loss:  1.1246015429496765\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 6 17  7]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.8511165380477905\n",
      "Inner Loss:  1.2697410583496094\n",
      "Inner Loss:  1.1741901636123657\n",
      "[[4 5 7]\n",
      " [7 3 4]\n",
      " [0 0 0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.7058733701705933\n",
      "Inner Loss:  2.068925678730011\n",
      "Inner Loss:  1.0950568914413452\n",
      "[[ 1  0  4]\n",
      " [ 1  0  0]\n",
      " [10  5  9]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.988616943359375\n",
      "Inner Loss:  1.4485803842544556\n",
      "Inner Loss:  1.2443706393241882\n",
      "[[5 2 1]\n",
      " [8 5 8]\n",
      " [0 1 0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.9177252054214478\n",
      "Inner Loss:  1.8259230256080627\n",
      "Inner Loss:  1.1134650111198425\n",
      "[[8 5 4]\n",
      " [0 0 0]\n",
      " [2 4 7]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.3661640882492065\n",
      "Inner Loss:  2.5962350368499756\n",
      "Inner Loss:  1.1923047304153442\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 11  9]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.190192937850952\n",
      "Inner Loss:  2.01869398355484\n",
      "Inner Loss:  1.2373313307762146\n",
      "[[ 9  6 13]\n",
      " [ 0  0  0]\n",
      " [ 0  2  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.9856960773468018\n",
      "Inner Loss:  2.1690266132354736\n",
      "Inner Loss:  1.0878934264183044\n",
      "[[9 3 7]\n",
      " [0 0 0]\n",
      " [3 6 2]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.733704566955566\n",
      "Inner Loss:  1.6287987232208252\n",
      "Inner Loss:  1.0986317992210388\n",
      "[[15 11  4]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.783361077308655\n",
      "Inner Loss:  1.9486995935440063\n",
      "Inner Loss:  1.134499728679657\n",
      "[[12  9  7]\n",
      " [ 0  0  0]\n",
      " [ 1  0  1]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.9677112102508545\n",
      "Inner Loss:  2.0806689262390137\n",
      "Inner Loss:  1.1392689943313599\n",
      "[[12  7  8]\n",
      " [ 0  0  0]\n",
      " [ 2  1  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.4364997148513794\n",
      "Inner Loss:  1.2055379152297974\n",
      "Inner Loss:  1.1366995573043823\n",
      "[[ 8 16  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.3486971855163574\n",
      "Inner Loss:  1.287413239479065\n",
      "Inner Loss:  1.1058874130249023\n",
      "[[10 14  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "Step: 7 \ttraining Acc: 0.3416666666666667\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.5552449226379395\n",
      "Inner Loss:  1.9466689825057983\n",
      "Inner Loss:  1.3034251928329468\n",
      "[[ 0  1  0]\n",
      " [10  5 11]\n",
      " [ 2  0  1]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.405997276306152\n",
      "Inner Loss:  1.2286595702171326\n",
      "Inner Loss:  1.1158621907234192\n",
      "[[ 8 13  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.6541056632995605\n",
      "Inner Loss:  1.6777973771095276\n",
      "Inner Loss:  1.156217634677887\n",
      "[[0 0 0]\n",
      " [4 3 4]\n",
      " [6 8 5]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.329430818557739\n",
      "Inner Loss:  1.5897969603538513\n",
      "Inner Loss:  1.1161140203475952\n",
      "[[10  5 12]\n",
      " [ 0  0  0]\n",
      " [ 2  1  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.606566548347473\n",
      "Inner Loss:  1.5146769285202026\n",
      "Inner Loss:  1.1153603196144104\n",
      "[[ 0  0  0]\n",
      " [ 1  0  1]\n",
      " [ 6 10 12]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.231552004814148\n",
      "Inner Loss:  1.9268580675125122\n",
      "Inner Loss:  1.298853874206543\n",
      "[[ 0  0  0]\n",
      " [10  9 11]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.183729410171509\n",
      "Inner Loss:  1.7502543926239014\n",
      "Inner Loss:  1.15046888589859\n",
      "[[ 0  0  0]\n",
      " [ 7 11 12]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.907354116439819\n",
      "Inner Loss:  1.6044508814811707\n",
      "Inner Loss:  1.2000900506973267\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [14  6 10]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.30361795425415\n",
      "Inner Loss:  1.7051144242286682\n",
      "Inner Loss:  1.1181889176368713\n",
      "[[ 0  1  1]\n",
      " [ 0  1  0]\n",
      " [11 11  5]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.377265095710754\n",
      "Inner Loss:  1.9435067176818848\n",
      "Inner Loss:  1.329318344593048\n",
      "[[6 2 5]\n",
      " [0 0 0]\n",
      " [6 3 8]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.716745376586914\n",
      "Inner Loss:  1.8410516381263733\n",
      "Inner Loss:  1.2245290279388428\n",
      "[[ 0  0  0]\n",
      " [11 11  8]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.459782958030701\n",
      "Inner Loss:  1.8707656860351562\n",
      "Inner Loss:  1.2533026337623596\n",
      "[[ 0  0  0]\n",
      " [12  7 11]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.779156684875488\n",
      "Inner Loss:  1.31235009431839\n",
      "Inner Loss:  1.1805722117424011\n",
      "[[ 0  3  3]\n",
      " [ 0  0  1]\n",
      " [10  6  7]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.668551445007324\n",
      "Inner Loss:  1.4121233820915222\n",
      "Inner Loss:  1.1210357546806335\n",
      "[[9 7 5]\n",
      " [0 0 0]\n",
      " [1 4 4]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.16448974609375\n",
      "Inner Loss:  1.58316171169281\n",
      "Inner Loss:  1.1164441108703613\n",
      "[[ 0  0  0]\n",
      " [10 14  6]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.269405961036682\n",
      "Inner Loss:  1.7357980608940125\n",
      "Inner Loss:  1.1292691826820374\n",
      "[[ 0  0  0]\n",
      " [15  8  6]\n",
      " [ 0  1  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.19407856464386\n",
      "Inner Loss:  2.1286879181861877\n",
      "Inner Loss:  1.332670509815216\n",
      "[[10  8  2]\n",
      " [ 0  0  0]\n",
      " [ 4  3  3]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  6.771161794662476\n",
      "Inner Loss:  1.2851498126983643\n",
      "Inner Loss:  1.1352732181549072\n",
      "[[8 1 2]\n",
      " [0 0 0]\n",
      " [7 9 3]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.701862454414368\n",
      "Inner Loss:  1.4737254977226257\n",
      "Inner Loss:  1.1183599829673767\n",
      "[[ 1  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 17  4]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.352496862411499\n",
      "Inner Loss:  1.850829541683197\n",
      "Inner Loss:  1.1989448070526123\n",
      "[[ 0  1  0]\n",
      " [ 9 10 10]\n",
      " [ 0  0  0]]\n",
      "Step: 8 \ttraining Acc: 0.32166666666666666\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.8848594427108765\n",
      "Inner Loss:  1.9937568306922913\n",
      "Inner Loss:  1.3728466033935547\n",
      "[[ 5  5 15]\n",
      " [ 0  0  0]\n",
      " [ 2  2  1]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.469674348831177\n",
      "Inner Loss:  1.8540655374526978\n",
      "Inner Loss:  1.3109023571014404\n",
      "[[ 0  0  0]\n",
      " [12 11  7]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  5.171706914901733\n",
      "Inner Loss:  1.9940897226333618\n",
      "Inner Loss:  1.3531813621520996\n",
      "[[9 8 7]\n",
      " [2 2 2]\n",
      " [0 0 0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.888990879058838\n",
      "Inner Loss:  1.9779576063156128\n",
      "Inner Loss:  1.3615770936012268\n",
      "[[ 3  3  3]\n",
      " [ 4 11  6]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.383208870887756\n",
      "Inner Loss:  1.9979339838027954\n",
      "Inner Loss:  1.3405967354774475\n",
      "[[12  6  5]\n",
      " [ 0  0  0]\n",
      " [ 4  3  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.3448522090911865\n",
      "Inner Loss:  1.9798016548156738\n",
      "Inner Loss:  1.342444658279419\n",
      "[[4 4 4]\n",
      " [7 7 4]\n",
      " [0 0 0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.902682542800903\n",
      "Inner Loss:  1.9311293363571167\n",
      "Inner Loss:  1.334986686706543\n",
      "[[6 4 3]\n",
      " [4 8 3]\n",
      " [0 1 1]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.60670018196106\n",
      "Inner Loss:  2.0127774477005005\n",
      "Inner Loss:  1.3699410557746887\n",
      "[[ 8 10  4]\n",
      " [ 1  1  1]\n",
      " [ 2  2  1]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.3940417766571045\n",
      "Inner Loss:  1.9313516020774841\n",
      "Inner Loss:  1.2977843880653381\n",
      "[[ 0  0  0]\n",
      " [ 5 12 13]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.029805898666382\n",
      "Inner Loss:  1.9803032875061035\n",
      "Inner Loss:  1.3711544275283813\n",
      "[[5 7 6]\n",
      " [3 5 4]\n",
      " [0 0 0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.687501907348633\n",
      "Inner Loss:  1.9587652683258057\n",
      "Inner Loss:  1.333341896533966\n",
      "[[ 1  1  0]\n",
      " [ 6 10 12]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.214844465255737\n",
      "Inner Loss:  1.9327734112739563\n",
      "Inner Loss:  1.310655415058136\n",
      "[[ 0  0  0]\n",
      " [11  9 10]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.876897096633911\n",
      "Inner Loss:  1.8608583807945251\n",
      "Inner Loss:  1.3114100694656372\n",
      "[[ 0  4  0]\n",
      " [12 10  4]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  3.896848678588867\n",
      "Inner Loss:  1.812502920627594\n",
      "Inner Loss:  1.2793529033660889\n",
      "[[ 0  0  0]\n",
      " [11 12  7]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.920105934143066\n",
      "Inner Loss:  2.1347615718841553\n",
      "Inner Loss:  1.409434974193573\n",
      "[[12  6  9]\n",
      " [ 0  0  0]\n",
      " [ 1  1  1]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.525853633880615\n",
      "Inner Loss:  1.8356562852859497\n",
      "Inner Loss:  1.268552005290985\n",
      "[[ 0  0  0]\n",
      " [ 7 13 10]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.656168580055237\n",
      "Inner Loss:  1.9095011353492737\n",
      "Inner Loss:  1.358039140701294\n",
      "[[ 2  0  1]\n",
      " [ 4 13  8]\n",
      " [ 0  0  2]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.260498046875\n",
      "Inner Loss:  1.8177241086959839\n",
      "Inner Loss:  1.3022725582122803\n",
      "[[ 0  3  0]\n",
      " [ 7  6 14]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.8973917961120605\n",
      "Inner Loss:  1.8957691192626953\n",
      "Inner Loss:  1.2876408100128174\n",
      "[[ 0  0  0]\n",
      " [10  9 11]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.026570558547974\n",
      "Inner Loss:  1.9228540658950806\n",
      "Inner Loss:  1.3371394872665405\n",
      "[[3 3 3]\n",
      " [6 8 7]\n",
      " [0 0 0]]\n",
      "Step: 9 \ttraining Acc: 0.37166666666666665\n",
      "----Task 0 ----\n",
      "Inner Loss:  6.003097295761108\n",
      "Inner Loss:  2.9745694398880005\n",
      "Inner Loss:  1.1112737655639648\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12 12  6]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.401392459869385\n",
      "Inner Loss:  2.7590248584747314\n",
      "Inner Loss:  1.1977293491363525\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [14  9  7]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.748520135879517\n",
      "Inner Loss:  2.8947540521621704\n",
      "Inner Loss:  1.0746836066246033\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 14  5]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.7799599170684814\n",
      "Inner Loss:  2.8407024145126343\n",
      "Inner Loss:  1.2508986592292786\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 11  8]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.456598520278931\n",
      "Inner Loss:  2.450361728668213\n",
      "Inner Loss:  1.3200550079345703\n",
      "[[ 0  0  0]\n",
      " [ 9 13  7]\n",
      " [ 0  0  1]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.900840997695923\n",
      "Inner Loss:  2.449895739555359\n",
      "Inner Loss:  1.3309956789016724\n",
      "[[ 0  0  0]\n",
      " [15  8  5]\n",
      " [ 1  0  1]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  6.426546096801758\n",
      "Inner Loss:  2.261655807495117\n",
      "Inner Loss:  1.4154090881347656\n",
      "[[ 0  0  0]\n",
      " [14  6 10]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.4936442375183105\n",
      "Inner Loss:  2.764270544052124\n",
      "Inner Loss:  1.1452078223228455\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10  7 13]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.347410440444946\n",
      "Inner Loss:  2.5048298239707947\n",
      "Inner Loss:  1.260587453842163\n",
      "[[0 0 0]\n",
      " [9 5 9]\n",
      " [1 5 1]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.871301651000977\n",
      "Inner Loss:  2.6505954265594482\n",
      "Inner Loss:  1.1970629692077637\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  9  9]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.4219255447387695\n",
      "Inner Loss:  2.24136483669281\n",
      "Inner Loss:  1.4352880716323853\n",
      "[[ 0  0  0]\n",
      " [ 6 10 14]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.954137802124023\n",
      "Inner Loss:  2.611119031906128\n",
      "Inner Loss:  1.2956206798553467\n",
      "[[ 0  0  0]\n",
      " [ 2  3  0]\n",
      " [12  7  6]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.4045000076293945\n",
      "Inner Loss:  2.8069409132003784\n",
      "Inner Loss:  1.1504183411598206\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12 11  7]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.966528654098511\n",
      "Inner Loss:  2.689490795135498\n",
      "Inner Loss:  1.3010689616203308\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12 13  5]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  5.707616567611694\n",
      "Inner Loss:  2.556772470474243\n",
      "Inner Loss:  1.375036358833313\n",
      "[[ 0  0  0]\n",
      " [10  2  9]\n",
      " [ 3  4  2]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.160207390785217\n",
      "Inner Loss:  2.883355975151062\n",
      "Inner Loss:  1.1135116219520569\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 12  7]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  6.0160231590271\n",
      "Inner Loss:  2.525255799293518\n",
      "Inner Loss:  1.2884820699691772\n",
      "[[ 0  0  0]\n",
      " [ 2  1  3]\n",
      " [ 6  6 12]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.747121095657349\n",
      "Inner Loss:  2.832014799118042\n",
      "Inner Loss:  1.2470672130584717\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [14 11  5]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.931171655654907\n",
      "Inner Loss:  2.761007308959961\n",
      "Inner Loss:  1.1586547493934631\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 13  9]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.726011514663696\n",
      "Inner Loss:  2.675761342048645\n",
      "Inner Loss:  1.3245540857315063\n",
      "[[0 0 0]\n",
      " [5 3 7]\n",
      " [5 8 2]]\n",
      "Step: 10 \ttraining Acc: 0.26166666666666666\n",
      "\n",
      "-----------------Testing Mode-----------------\n",
      "\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.65413498878479\n",
      "Inner Loss:  3.029046058654785\n",
      "Inner Loss:  1.7310510277748108\n",
      "Inner Loss:  1.209239661693573\n",
      "Inner Loss:  1.1199215054512024\n",
      "Inner Loss:  1.1204511523246765\n",
      "Inner Loss:  1.080340564250946\n",
      "Inner Loss:  1.0840801000595093\n",
      "Inner Loss:  1.0806664824485779\n",
      "Inner Loss:  1.0850257873535156\n",
      "[[ 4 10 14]\n",
      " [ 2  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  6.480553150177002\n",
      "Inner Loss:  3.314550042152405\n",
      "Inner Loss:  2.0287371277809143\n",
      "Inner Loss:  1.1185277104377747\n",
      "Inner Loss:  1.2010747194290161\n",
      "Inner Loss:  1.1191875338554382\n",
      "Inner Loss:  1.133919894695282\n",
      "Inner Loss:  1.1050957441329956\n",
      "Inner Loss:  1.1068057417869568\n",
      "Inner Loss:  1.1113463640213013\n",
      "[[ 4  6 11]\n",
      " [ 2  0  2]\n",
      " [ 1  2  2]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.4872201681137085\n",
      "Inner Loss:  3.6065725088119507\n",
      "Inner Loss:  2.221190929412842\n",
      "Inner Loss:  1.0887969136238098\n",
      "Inner Loss:  1.235823392868042\n",
      "Inner Loss:  1.0844141840934753\n",
      "Inner Loss:  1.1081034541130066\n",
      "Inner Loss:  1.0799450874328613\n",
      "Inner Loss:  1.083663821220398\n",
      "Inner Loss:  1.0768114924430847\n",
      "[[ 0  0  0]\n",
      " [ 9 11 10]\n",
      " [ 0  0  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.400502681732178\n",
      "Inner Loss:  3.474042534828186\n",
      "Inner Loss:  2.1886117458343506\n",
      "Inner Loss:  1.1121020317077637\n",
      "Inner Loss:  1.231041669845581\n",
      "Inner Loss:  1.0915303826332092\n",
      "Inner Loss:  1.1124297976493835\n",
      "Inner Loss:  1.0888969898223877\n",
      "Inner Loss:  1.0855764746665955\n",
      "Inner Loss:  1.0757103562355042\n",
      "[[ 1  2  0]\n",
      " [ 4 11  9]\n",
      " [ 2  1  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.410477876663208\n",
      "Inner Loss:  3.301072597503662\n",
      "Inner Loss:  1.9603226780891418\n",
      "Inner Loss:  1.153727948665619\n",
      "Inner Loss:  1.1939533948898315\n",
      "Inner Loss:  1.1539031267166138\n",
      "Inner Loss:  1.1111479997634888\n",
      "Inner Loss:  1.0971952676773071\n",
      "Inner Loss:  1.1187173128128052\n",
      "Inner Loss:  1.1051172018051147\n",
      "[[4 2 5]\n",
      " [7 6 5]\n",
      " [1 0 0]]\n",
      "Step: 10 Test F1: 0.2866666666666667\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.599688529968262\n",
      "Inner Loss:  3.37696373462677\n",
      "Inner Loss:  1.9567234516143799\n",
      "[[9 7 6]\n",
      " [2 4 2]\n",
      " [0 0 0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.843768835067749\n",
      "Inner Loss:  3.1327372789382935\n",
      "Inner Loss:  2.00506854057312\n",
      "[[ 9  7 13]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  6.39971137046814\n",
      "Inner Loss:  3.8594471216201782\n",
      "Inner Loss:  2.0852097868919373\n",
      "[[ 9 11  9]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.109462022781372\n",
      "Inner Loss:  3.0534756183624268\n",
      "Inner Loss:  1.9196978211402893\n",
      "[[8 9 9]\n",
      " [1 1 2]\n",
      " [0 0 0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  6.527270317077637\n",
      "Inner Loss:  3.0261601209640503\n",
      "Inner Loss:  1.6503131985664368\n",
      "[[10 10  8]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  6.068497896194458\n",
      "Inner Loss:  2.948575973510742\n",
      "Inner Loss:  1.7837736010551453\n",
      "[[11  8  5]\n",
      " [ 1  3  2]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.030520081520081\n",
      "Inner Loss:  3.6642532348632812\n",
      "Inner Loss:  2.1291434168815613\n",
      "[[12  8  6]\n",
      " [ 1  1  2]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  6.696826457977295\n",
      "Inner Loss:  3.208991765975952\n",
      "Inner Loss:  1.8860164880752563\n",
      "[[ 9 12  8]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.050553917884827\n",
      "Inner Loss:  3.4155689477920532\n",
      "Inner Loss:  2.0518783926963806\n",
      "[[ 6 14  7]\n",
      " [ 2  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.79780387878418\n",
      "Inner Loss:  3.7239831686019897\n",
      "Inner Loss:  2.1524606943130493\n",
      "[[ 6  8 14]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.949894070625305\n",
      "Inner Loss:  3.703603506088257\n",
      "Inner Loss:  1.9917598962783813\n",
      "[[ 7 10 11]\n",
      " [ 0  2  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.919724702835083\n",
      "Inner Loss:  3.8667776584625244\n",
      "Inner Loss:  2.0570186972618103\n",
      "[[ 8  9 11]\n",
      " [ 0  1  1]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.408609628677368\n",
      "Inner Loss:  3.3235491514205933\n",
      "Inner Loss:  1.9714443683624268\n",
      "[[ 9 12  8]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.565574526786804\n",
      "Inner Loss:  3.667511224746704\n",
      "Inner Loss:  2.156028628349304\n",
      "[[12 12  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  6.564659118652344\n",
      "Inner Loss:  3.0404107570648193\n",
      "Inner Loss:  1.872907817363739\n",
      "[[10 11  7]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  6.551078796386719\n",
      "Inner Loss:  3.1353919506073\n",
      "Inner Loss:  1.9988770484924316\n",
      "[[10  5 12]\n",
      " [ 3  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.716640949249268\n",
      "Inner Loss:  3.8234671354293823\n",
      "Inner Loss:  2.0801215767860413\n",
      "[[7 6 8]\n",
      " [5 3 1]\n",
      " [0 0 0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.1783082485198975\n",
      "Inner Loss:  3.534379005432129\n",
      "Inner Loss:  2.1153072118759155\n",
      "[[ 8 13  8]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.207855463027954\n",
      "Inner Loss:  3.399651050567627\n",
      "Inner Loss:  1.73699551820755\n",
      "[[8 7 9]\n",
      " [1 2 3]\n",
      " [0 0 0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  6.0831427574157715\n",
      "Inner Loss:  3.6557639837265015\n",
      "Inner Loss:  2.2170227766036987\n",
      "[[10  9 10]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "Step: 11 \ttraining Acc: 0.3333333333333333\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.54923677444458\n",
      "Inner Loss:  3.601910948753357\n",
      "Inner Loss:  1.1675150394439697\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13  7 10]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.548344135284424\n",
      "Inner Loss:  3.572344660758972\n",
      "Inner Loss:  1.434848666191101\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [16  5  9]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  5.377785801887512\n",
      "Inner Loss:  3.385277032852173\n",
      "Inner Loss:  1.3507478833198547\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 3 17 10]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.160640478134155\n",
      "Inner Loss:  3.105948805809021\n",
      "Inner Loss:  1.3594986200332642\n",
      "[[ 1  2  0]\n",
      " [ 0  0  0]\n",
      " [10  6 11]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.774462699890137\n",
      "Inner Loss:  3.1457396745681763\n",
      "Inner Loss:  1.4066526293754578\n",
      "[[3 9 6]\n",
      " [0 1 1]\n",
      " [2 3 5]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.726006507873535\n",
      "Inner Loss:  2.822385549545288\n",
      "Inner Loss:  1.2360449433326721\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8  9 13]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  6.030996322631836\n",
      "Inner Loss:  3.7253260612487793\n",
      "Inner Loss:  1.1483042240142822\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 6 14 10]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.712031364440918\n",
      "Inner Loss:  3.0100157260894775\n",
      "Inner Loss:  1.1510481238365173\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 13  9]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.8253055810928345\n",
      "Inner Loss:  3.110746741294861\n",
      "Inner Loss:  1.1980713605880737\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [15  8  7]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.939574599266052\n",
      "Inner Loss:  3.226177215576172\n",
      "Inner Loss:  1.3314629197120667\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  8 10]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.333479523658752\n",
      "Inner Loss:  3.3145521879196167\n",
      "Inner Loss:  1.130731463432312\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 5 14 11]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.290760517120361\n",
      "Inner Loss:  3.0745272636413574\n",
      "Inner Loss:  1.189075231552124\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13 12  5]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  6.409064769744873\n",
      "Inner Loss:  3.055207133293152\n",
      "Inner Loss:  1.3130961656570435\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 12  9]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.444056510925293\n",
      "Inner Loss:  3.3383675813674927\n",
      "Inner Loss:  1.1401393413543701\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 11 12]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  5.498039364814758\n",
      "Inner Loss:  3.4119895696640015\n",
      "Inner Loss:  1.180432379245758\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [14  4 12]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  6.079235553741455\n",
      "Inner Loss:  3.1839637756347656\n",
      "Inner Loss:  1.481972575187683\n",
      "[[8 4 6]\n",
      " [1 2 0]\n",
      " [2 5 2]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.8273656368255615\n",
      "Inner Loss:  3.336891293525696\n",
      "Inner Loss:  1.5217984914779663\n",
      "[[6 7 4]\n",
      " [0 1 0]\n",
      " [5 4 3]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.834691762924194\n",
      "Inner Loss:  3.5565173625946045\n",
      "Inner Loss:  1.350206971168518\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10  8 12]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.118544816970825\n",
      "Inner Loss:  2.9263116121292114\n",
      "Inner Loss:  1.2834050059318542\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 6 15  9]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.244676470756531\n",
      "Inner Loss:  3.034559488296509\n",
      "Inner Loss:  1.5975701808929443\n",
      "[[8 8 9]\n",
      " [2 2 1]\n",
      " [0 0 0]]\n",
      "Step: 12 \ttraining Acc: 0.335\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.2685564756393433\n",
      "Inner Loss:  1.4540216326713562\n",
      "Inner Loss:  1.1658302545547485\n",
      "[[0 0 0]\n",
      " [3 3 0]\n",
      " [8 9 7]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.787065863609314\n",
      "Inner Loss:  1.4908700585365295\n",
      "Inner Loss:  1.1622651815414429\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12 11  7]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.258999347686768\n",
      "Inner Loss:  2.5282787084579468\n",
      "Inner Loss:  1.1449467539787292\n",
      "[[ 1  0  0]\n",
      " [ 9  6 14]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.025869131088257\n",
      "Inner Loss:  1.4749245643615723\n",
      "Inner Loss:  1.0637975335121155\n",
      "[[ 7 13  9]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.0244140625\n",
      "Inner Loss:  1.6003363132476807\n",
      "Inner Loss:  1.2975473999977112\n",
      "[[ 0  0  0]\n",
      " [ 9 12  9]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.137320876121521\n",
      "Inner Loss:  1.6070051789283752\n",
      "Inner Loss:  1.2105796337127686\n",
      "[[ 0  1  0]\n",
      " [10  5 14]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.647397994995117\n",
      "Inner Loss:  2.267937183380127\n",
      "Inner Loss:  1.2936483025550842\n",
      "[[6 9 9]\n",
      " [0 0 0]\n",
      " [2 3 1]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.371412634849548\n",
      "Inner Loss:  1.673213005065918\n",
      "Inner Loss:  1.2752764225006104\n",
      "[[3 5 3]\n",
      " [2 1 4]\n",
      " [5 5 2]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.142138123512268\n",
      "Inner Loss:  2.411072611808777\n",
      "Inner Loss:  1.2240416407585144\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 10 10]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.370420217514038\n",
      "Inner Loss:  1.3457043766975403\n",
      "Inner Loss:  1.1529262065887451\n",
      "[[ 1  2  3]\n",
      " [10  5  8]\n",
      " [ 0  0  1]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.868408441543579\n",
      "Inner Loss:  1.7297136783599854\n",
      "Inner Loss:  1.2958590984344482\n",
      "[[ 0  0  0]\n",
      " [ 7 14  9]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.796608090400696\n",
      "Inner Loss:  1.5024774074554443\n",
      "Inner Loss:  1.1423413753509521\n",
      "[[ 0  0  0]\n",
      " [ 6 11  6]\n",
      " [ 2  5  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.880279779434204\n",
      "Inner Loss:  2.4981024265289307\n",
      "Inner Loss:  1.4592439532279968\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 10 10]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.491350889205933\n",
      "Inner Loss:  1.8211011290550232\n",
      "Inner Loss:  1.392666518688202\n",
      "[[6 4 3]\n",
      " [7 4 6]\n",
      " [0 0 0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.445206642150879\n",
      "Inner Loss:  1.4900266528129578\n",
      "Inner Loss:  1.202344834804535\n",
      "[[ 0  0  0]\n",
      " [ 0  1  3]\n",
      " [10  7  9]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.460270166397095\n",
      "Inner Loss:  1.7437387704849243\n",
      "Inner Loss:  1.3986232280731201\n",
      "[[5 7 8]\n",
      " [5 2 3]\n",
      " [0 0 0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.1581209897994995\n",
      "Inner Loss:  1.3165909051895142\n",
      "Inner Loss:  1.132911741733551\n",
      "[[ 0  0  0]\n",
      " [ 7 12 11]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.607672214508057\n",
      "Inner Loss:  1.3678714036941528\n",
      "Inner Loss:  1.24772310256958\n",
      "[[4 7 8]\n",
      " [2 5 4]\n",
      " [0 0 0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.8974119424819946\n",
      "Inner Loss:  1.4879714250564575\n",
      "Inner Loss:  1.2076244950294495\n",
      "[[ 0  0  0]\n",
      " [ 2  2  1]\n",
      " [ 4  9 12]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.277145624160767\n",
      "Inner Loss:  2.3188170790672302\n",
      "Inner Loss:  1.1126976609230042\n",
      "[[2 2 2]\n",
      " [3 1 0]\n",
      " [5 8 7]]\n",
      "Step: 13 \ttraining Acc: 0.3083333333333333\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.939708232879639\n",
      "Inner Loss:  2.5351462364196777\n",
      "Inner Loss:  1.475460946559906\n",
      "[[ 8 11 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.859497785568237\n",
      "Inner Loss:  2.73776912689209\n",
      "Inner Loss:  1.2928757667541504\n",
      "[[11 11  7]\n",
      " [ 0  0  0]\n",
      " [ 1  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.916653394699097\n",
      "Inner Loss:  2.5482157468795776\n",
      "Inner Loss:  1.2188788652420044\n",
      "[[ 4  8 10]\n",
      " [ 0  0  0]\n",
      " [ 4  1  3]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.58782172203064\n",
      "Inner Loss:  2.864385485649109\n",
      "Inner Loss:  1.219474196434021\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 10 11]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.010376453399658\n",
      "Inner Loss:  3.066694974899292\n",
      "Inner Loss:  1.2546223998069763\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 14  9]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.407167196273804\n",
      "Inner Loss:  2.593711495399475\n",
      "Inner Loss:  1.3835873007774353\n",
      "[[ 5 14 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.386001706123352\n",
      "Inner Loss:  2.804196000099182\n",
      "Inner Loss:  1.1703689098358154\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 10 10]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.651508331298828\n",
      "Inner Loss:  2.3045302629470825\n",
      "Inner Loss:  1.357980191707611\n",
      "[[11 10  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.933371901512146\n",
      "Inner Loss:  2.8874720335006714\n",
      "Inner Loss:  1.1513893008232117\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 10 12]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.55563497543335\n",
      "Inner Loss:  2.436941146850586\n",
      "Inner Loss:  1.1623626351356506\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7  9 14]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.575092554092407\n",
      "Inner Loss:  2.7165902853012085\n",
      "Inner Loss:  1.224973201751709\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 5 16  9]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.7235939502716064\n",
      "Inner Loss:  2.557944178581238\n",
      "Inner Loss:  1.2680100798606873\n",
      "[[ 6 10 13]\n",
      " [ 0  0  0]\n",
      " [ 1  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.025761723518372\n",
      "Inner Loss:  2.5586758852005005\n",
      "Inner Loss:  1.2087337374687195\n",
      "[[ 1  1  2]\n",
      " [ 0  0  0]\n",
      " [ 4  9 13]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.27605676651001\n",
      "Inner Loss:  2.4213597774505615\n",
      "Inner Loss:  1.3468618392944336\n",
      "[[10 13  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.692667841911316\n",
      "Inner Loss:  2.8563950061798096\n",
      "Inner Loss:  1.195686936378479\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10  9 11]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  6.155471563339233\n",
      "Inner Loss:  1.8636285662651062\n",
      "Inner Loss:  1.3495652079582214\n",
      "[[ 7  5 10]\n",
      " [ 3  3  2]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.961956858634949\n",
      "Inner Loss:  2.5574718713760376\n",
      "Inner Loss:  1.1158475279808044\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [14  3 13]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.3677496910095215\n",
      "Inner Loss:  2.7507379055023193\n",
      "Inner Loss:  1.1186605095863342\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 5 13 12]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.9763699769973755\n",
      "Inner Loss:  2.805248498916626\n",
      "Inner Loss:  1.1149780750274658\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  9  9]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  6.022481679916382\n",
      "Inner Loss:  2.6575030088424683\n",
      "Inner Loss:  1.1756190657615662\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 13  6]]\n",
      "Step: 14 \ttraining Acc: 0.33\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.873731374740601\n",
      "Inner Loss:  2.4409550428390503\n",
      "Inner Loss:  1.2010060548782349\n",
      "[[11 13  5]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.472135543823242\n",
      "Inner Loss:  2.167689800262451\n",
      "Inner Loss:  1.3419328331947327\n",
      "[[10  9  6]\n",
      " [ 2  1  2]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  5.142729997634888\n",
      "Inner Loss:  2.6929705142974854\n",
      "Inner Loss:  1.3258150815963745\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 10  9]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.627866268157959\n",
      "Inner Loss:  2.4947746992111206\n",
      "Inner Loss:  1.3259578347206116\n",
      "[[ 0  2  0]\n",
      " [ 0  0  0]\n",
      " [ 5 12 11]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.749265909194946\n",
      "Inner Loss:  2.0981833934783936\n",
      "Inner Loss:  1.2283684611320496\n",
      "[[5 6 3]\n",
      " [4 6 6]\n",
      " [0 0 0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.437189817428589\n",
      "Inner Loss:  3.0939764976501465\n",
      "Inner Loss:  1.2949100732803345\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 13 10]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.098234415054321\n",
      "Inner Loss:  2.8467248678207397\n",
      "Inner Loss:  1.4389726519584656\n",
      "[[9 9 6]\n",
      " [0 0 0]\n",
      " [1 2 3]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.595879554748535\n",
      "Inner Loss:  2.0164804458618164\n",
      "Inner Loss:  1.2898576259613037\n",
      "[[ 5  6 10]\n",
      " [ 3  4  2]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.697758913040161\n",
      "Inner Loss:  3.0765910148620605\n",
      "Inner Loss:  1.393008291721344\n",
      "[[5 7 5]\n",
      " [0 0 0]\n",
      " [6 4 3]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.206710338592529\n",
      "Inner Loss:  2.0971859097480774\n",
      "Inner Loss:  1.3952690958976746\n",
      "[[8 7 8]\n",
      " [2 4 1]\n",
      " [0 0 0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.533218622207642\n",
      "Inner Loss:  2.4471547603607178\n",
      "Inner Loss:  1.1710978746414185\n",
      "[[ 7 16  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.5684895515441895\n",
      "Inner Loss:  2.18098521232605\n",
      "Inner Loss:  1.3819880485534668\n",
      "[[ 7 11 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.029050827026367\n",
      "Inner Loss:  2.8895466327667236\n",
      "Inner Loss:  1.4552341103553772\n",
      "[[ 9  8 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.728691339492798\n",
      "Inner Loss:  2.015352487564087\n",
      "Inner Loss:  1.4078587293624878\n",
      "[[11  5 14]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.841759920120239\n",
      "Inner Loss:  2.3647581338882446\n",
      "Inner Loss:  1.322051763534546\n",
      "[[ 7 10 11]\n",
      " [ 0  2  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.516430497169495\n",
      "Inner Loss:  3.181365132331848\n",
      "Inner Loss:  1.4879485368728638\n",
      "[[15  9  5]\n",
      " [ 0  0  0]\n",
      " [ 0  1  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.683860778808594\n",
      "Inner Loss:  2.0948290824890137\n",
      "Inner Loss:  1.3977677822113037\n",
      "[[11  8  6]\n",
      " [ 0  4  1]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.039166688919067\n",
      "Inner Loss:  2.899978756904602\n",
      "Inner Loss:  1.2145758867263794\n",
      "[[12  5 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.165936708450317\n",
      "Inner Loss:  2.794786214828491\n",
      "Inner Loss:  1.2840591073036194\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 12 11]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.432279109954834\n",
      "Inner Loss:  1.8818813562393188\n",
      "Inner Loss:  1.348021924495697\n",
      "[[ 5 13  3]\n",
      " [ 3  4  2]\n",
      " [ 0  0  0]]\n",
      "Step: 15 \ttraining Acc: 0.34833333333333333\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.570111989974976\n",
      "Inner Loss:  2.73146915435791\n",
      "Inner Loss:  1.5906147360801697\n",
      "[[11 10  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.5694005489349365\n",
      "Inner Loss:  3.4115172624588013\n",
      "Inner Loss:  1.684201955795288\n",
      "[[13  4 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.9583704471588135\n",
      "Inner Loss:  2.9788155555725098\n",
      "Inner Loss:  1.6220848560333252\n",
      "[[ 8  9 12]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.3425610065460205\n",
      "Inner Loss:  2.732266068458557\n",
      "Inner Loss:  1.6505945920944214\n",
      "[[10 10 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.589527606964111\n",
      "Inner Loss:  3.2878957986831665\n",
      "Inner Loss:  1.5490780472755432\n",
      "[[ 6  9 12]\n",
      " [ 0  0  0]\n",
      " [ 3  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.101778507232666\n",
      "Inner Loss:  3.015009641647339\n",
      "Inner Loss:  1.599602222442627\n",
      "[[ 4 11 15]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.810521364212036\n",
      "Inner Loss:  2.523288369178772\n",
      "Inner Loss:  1.5992631912231445\n",
      "[[ 9 11 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.0421364307403564\n",
      "Inner Loss:  3.380945324897766\n",
      "Inner Loss:  1.7350186109542847\n",
      "[[ 9  8 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.9450061321258545\n",
      "Inner Loss:  3.0115580558776855\n",
      "Inner Loss:  1.6060323119163513\n",
      "[[ 7  9 14]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.038678407669067\n",
      "Inner Loss:  2.933969259262085\n",
      "Inner Loss:  1.6225656867027283\n",
      "[[ 7 15  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.039435386657715\n",
      "Inner Loss:  2.9048739671707153\n",
      "Inner Loss:  1.4038003087043762\n",
      "[[ 1  0  1]\n",
      " [ 0  0  0]\n",
      " [12 11  5]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.0588297843933105\n",
      "Inner Loss:  3.011347770690918\n",
      "Inner Loss:  1.6147862076759338\n",
      "[[14  7  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.26771879196167\n",
      "Inner Loss:  2.90293288230896\n",
      "Inner Loss:  1.52717787027359\n",
      "[[ 7 12  9]\n",
      " [ 1  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.594066143035889\n",
      "Inner Loss:  2.7052454948425293\n",
      "Inner Loss:  1.4593888521194458\n",
      "[[11  9  6]\n",
      " [ 2  0  2]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.559567928314209\n",
      "Inner Loss:  3.2360533475875854\n",
      "Inner Loss:  1.6237767338752747\n",
      "[[ 9  9 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.468665599822998\n",
      "Inner Loss:  2.677533745765686\n",
      "Inner Loss:  1.2958484292030334\n",
      "[[3 1 2]\n",
      " [0 0 2]\n",
      " [9 9 4]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.663089752197266\n",
      "Inner Loss:  2.653220772743225\n",
      "Inner Loss:  1.5572482347488403\n",
      "[[ 4 14 10]\n",
      " [ 0  1  1]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.721096992492676\n",
      "Inner Loss:  2.5617308616638184\n",
      "Inner Loss:  1.5882242918014526\n",
      "[[12 10  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.3780646324157715\n",
      "Inner Loss:  2.8829787969589233\n",
      "Inner Loss:  1.5240115523338318\n",
      "[[11  5 13]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.994622468948364\n",
      "Inner Loss:  3.0186996459960938\n",
      "Inner Loss:  1.6188915371894836\n",
      "[[11  7 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "Step: 16 \ttraining Acc: 0.295\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.917015552520752\n",
      "Inner Loss:  2.812636971473694\n",
      "Inner Loss:  1.1876336336135864\n",
      "[[ 9 10 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.898622274398804\n",
      "Inner Loss:  2.3351099491119385\n",
      "Inner Loss:  1.3914013504981995\n",
      "[[ 0  0  0]\n",
      " [10 12  8]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  5.511548280715942\n",
      "Inner Loss:  2.5318005084991455\n",
      "Inner Loss:  1.381799578666687\n",
      "[[ 0  0  0]\n",
      " [ 8 13  9]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.181061506271362\n",
      "Inner Loss:  2.778175950050354\n",
      "Inner Loss:  1.4519288539886475\n",
      "[[ 0  0  1]\n",
      " [ 6  8 15]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.682872295379639\n",
      "Inner Loss:  3.0174418687820435\n",
      "Inner Loss:  1.5481716990470886\n",
      "[[ 0  1  3]\n",
      " [ 7  6 12]\n",
      " [ 0  1  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.929174423217773\n",
      "Inner Loss:  2.811038851737976\n",
      "Inner Loss:  1.5381253361701965\n",
      "[[4 3 1]\n",
      " [9 4 9]\n",
      " [0 0 0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  6.08294153213501\n",
      "Inner Loss:  2.26819109916687\n",
      "Inner Loss:  1.380748450756073\n",
      "[[ 0  0  0]\n",
      " [11  8 11]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.679324388504028\n",
      "Inner Loss:  2.3983960151672363\n",
      "Inner Loss:  1.322845995426178\n",
      "[[ 0  0  0]\n",
      " [ 9  9 12]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.380709648132324\n",
      "Inner Loss:  2.431587338447571\n",
      "Inner Loss:  1.1599120497703552\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 6 13 11]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  6.022637128829956\n",
      "Inner Loss:  2.648691415786743\n",
      "Inner Loss:  1.3071130514144897\n",
      "[[ 8 13  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.602007627487183\n",
      "Inner Loss:  2.4422367811203003\n",
      "Inner Loss:  1.4769030213356018\n",
      "[[ 2  0  1]\n",
      " [11 12  4]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.9520180225372314\n",
      "Inner Loss:  2.2752861976623535\n",
      "Inner Loss:  1.417174756526947\n",
      "[[ 0  0  0]\n",
      " [17  8  5]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.040850639343262\n",
      "Inner Loss:  2.7702358961105347\n",
      "Inner Loss:  1.371629774570465\n",
      "[[ 0  0  0]\n",
      " [ 7 12 11]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.527367353439331\n",
      "Inner Loss:  2.4098379611968994\n",
      "Inner Loss:  1.2918038964271545\n",
      "[[ 0  0  0]\n",
      " [ 4 15 11]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  6.2923455238342285\n",
      "Inner Loss:  2.0894498229026794\n",
      "Inner Loss:  1.3000352382659912\n",
      "[[ 0  0  0]\n",
      " [13  9  8]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.360092878341675\n",
      "Inner Loss:  2.5408780574798584\n",
      "Inner Loss:  1.2065457105636597\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 12 10]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  6.018690824508667\n",
      "Inner Loss:  2.1248186826705933\n",
      "Inner Loss:  1.2301080822944641\n",
      "[[ 2  1  3]\n",
      " [ 7  5 10]\n",
      " [ 0  2  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.999242067337036\n",
      "Inner Loss:  2.1515523195266724\n",
      "Inner Loss:  1.2614014744758606\n",
      "[[ 0  1  1]\n",
      " [12  7  9]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  6.0072479248046875\n",
      "Inner Loss:  2.1566243171691895\n",
      "Inner Loss:  1.1718410849571228\n",
      "[[ 3  3  0]\n",
      " [ 0  1  0]\n",
      " [ 3 14  6]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.844255208969116\n",
      "Inner Loss:  2.2530877590179443\n",
      "Inner Loss:  1.3174147009849548\n",
      "[[ 0  0  0]\n",
      " [12  9  9]\n",
      " [ 0  0  0]]\n",
      "Step: 17 \ttraining Acc: 0.32166666666666666\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.744067430496216\n",
      "Inner Loss:  2.3933715224266052\n",
      "Inner Loss:  1.1589991450309753\n",
      "[[9 7 6]\n",
      " [4 2 2]\n",
      " [0 0 0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.760270357131958\n",
      "Inner Loss:  2.2820574045181274\n",
      "Inner Loss:  1.3789027333259583\n",
      "[[ 2  2  1]\n",
      " [ 3 12 10]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  5.302660226821899\n",
      "Inner Loss:  2.519239902496338\n",
      "Inner Loss:  1.2048135995864868\n",
      "[[ 7 13 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.889914512634277\n",
      "Inner Loss:  2.836294651031494\n",
      "Inner Loss:  1.1971802711486816\n",
      "[[11 11  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.7100584506988525\n",
      "Inner Loss:  2.20420378446579\n",
      "Inner Loss:  1.2021424174308777\n",
      "[[ 0  0  0]\n",
      " [ 3  1  1]\n",
      " [10  8  7]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.601472854614258\n",
      "Inner Loss:  2.6699471473693848\n",
      "Inner Loss:  1.2196971774101257\n",
      "[[ 8 12 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.346453905105591\n",
      "Inner Loss:  2.383976697921753\n",
      "Inner Loss:  1.2090103030204773\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11  8 11]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.725113153457642\n",
      "Inner Loss:  2.610005736351013\n",
      "Inner Loss:  1.2919576168060303\n",
      "[[ 6 11 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.953655958175659\n",
      "Inner Loss:  1.990723729133606\n",
      "Inner Loss:  1.3018832206726074\n",
      "[[9 9 9]\n",
      " [0 0 0]\n",
      " [0 2 1]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.233616590499878\n",
      "Inner Loss:  2.5418986082077026\n",
      "Inner Loss:  1.2655152678489685\n",
      "[[11 14  5]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.416074514389038\n",
      "Inner Loss:  2.605495810508728\n",
      "Inner Loss:  1.2135207653045654\n",
      "[[14  8  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.978714227676392\n",
      "Inner Loss:  2.6161922216415405\n",
      "Inner Loss:  1.1701704859733582\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11  6 13]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  6.008352518081665\n",
      "Inner Loss:  2.7754690647125244\n",
      "Inner Loss:  1.2660191059112549\n",
      "[[ 7 10 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.834397792816162\n",
      "Inner Loss:  2.543906569480896\n",
      "Inner Loss:  1.3128066658973694\n",
      "[[7 2 5]\n",
      " [7 6 3]\n",
      " [0 0 0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  5.322419881820679\n",
      "Inner Loss:  2.613446354866028\n",
      "Inner Loss:  1.235843539237976\n",
      "[[10  9 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.776670932769775\n",
      "Inner Loss:  2.7436541318893433\n",
      "Inner Loss:  1.2062970995903015\n",
      "[[ 8  9 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.6041576862335205\n",
      "Inner Loss:  2.773470163345337\n",
      "Inner Loss:  1.2056512236595154\n",
      "[[ 7 10 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.2616071701049805\n",
      "Inner Loss:  2.543806552886963\n",
      "Inner Loss:  1.2266664505004883\n",
      "[[ 9 11 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.663868188858032\n",
      "Inner Loss:  2.8052459955215454\n",
      "Inner Loss:  1.178060531616211\n",
      "[[10 11  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.5567967891693115\n",
      "Inner Loss:  2.016583263874054\n",
      "Inner Loss:  1.2265114784240723\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  9  9]]\n",
      "Step: 18 \ttraining Acc: 0.32833333333333325\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.945491075515747\n",
      "Inner Loss:  2.7051239013671875\n",
      "Inner Loss:  1.2602707147598267\n",
      "[[12  9  7]\n",
      " [ 0  0  0]\n",
      " [ 0  1  1]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.746791362762451\n",
      "Inner Loss:  2.841365337371826\n",
      "Inner Loss:  1.1783608198165894\n",
      "[[ 8 13  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  5.719852447509766\n",
      "Inner Loss:  3.024308443069458\n",
      "Inner Loss:  1.373583197593689\n",
      "[[11 11  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.362416982650757\n",
      "Inner Loss:  2.978259563446045\n",
      "Inner Loss:  1.539678692817688\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 11 10]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.400197267532349\n",
      "Inner Loss:  2.727073311805725\n",
      "Inner Loss:  1.1689414978027344\n",
      "[[10  9 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.152462959289551\n",
      "Inner Loss:  2.7785078287124634\n",
      "Inner Loss:  1.5564616918563843\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8  9 13]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.155186176300049\n",
      "Inner Loss:  2.662036657333374\n",
      "Inner Loss:  1.1660364866256714\n",
      "[[ 6  6 18]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.724120855331421\n",
      "Inner Loss:  3.1188846826553345\n",
      "Inner Loss:  1.4563573598861694\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 11  8]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.937903642654419\n",
      "Inner Loss:  3.1700778007507324\n",
      "Inner Loss:  1.6558687090873718\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 12 10]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.373822450637817\n",
      "Inner Loss:  2.451765775680542\n",
      "Inner Loss:  1.3589450120925903\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 13  6]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.555798768997192\n",
      "Inner Loss:  2.946134567260742\n",
      "Inner Loss:  1.222370684146881\n",
      "[[12 12  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.671629905700684\n",
      "Inner Loss:  3.0835161209106445\n",
      "Inner Loss:  1.3618663549423218\n",
      "[[11  8 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.580335378646851\n",
      "Inner Loss:  2.9456676244735718\n",
      "Inner Loss:  1.2486451268196106\n",
      "[[ 8 11 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.340818881988525\n",
      "Inner Loss:  2.899433970451355\n",
      "Inner Loss:  1.3865400552749634\n",
      "[[6 3 9]\n",
      " [0 0 0]\n",
      " [7 4 1]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  5.650130987167358\n",
      "Inner Loss:  2.823604941368103\n",
      "Inner Loss:  1.2805826663970947\n",
      "[[ 7 14  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.914758205413818\n",
      "Inner Loss:  2.8633313179016113\n",
      "Inner Loss:  1.135263204574585\n",
      "[[12 12  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.644856929779053\n",
      "Inner Loss:  2.9462188482284546\n",
      "Inner Loss:  1.6937944889068604\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 10 10]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.655946254730225\n",
      "Inner Loss:  2.8693116903305054\n",
      "Inner Loss:  1.3798479437828064\n",
      "[[13  9  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  6.221769094467163\n",
      "Inner Loss:  2.75230073928833\n",
      "Inner Loss:  1.1520808339118958\n",
      "[[2 2 1]\n",
      " [9 9 7]\n",
      " [0 0 0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.53574800491333\n",
      "Inner Loss:  3.016972780227661\n",
      "Inner Loss:  1.440394639968872\n",
      "[[ 0  1  2]\n",
      " [ 0  0  0]\n",
      " [ 9 13  5]]\n",
      "Step: 19 \ttraining Acc: 0.3183333333333333\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.422559022903442\n",
      "Inner Loss:  3.201706290245056\n",
      "Inner Loss:  1.6656315922737122\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 12 11]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.4613196849823\n",
      "Inner Loss:  3.2872254848480225\n",
      "Inner Loss:  1.6332754492759705\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 5 14 11]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.94611668586731\n",
      "Inner Loss:  2.9825695753097534\n",
      "Inner Loss:  1.6439303159713745\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  9  9]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.158293962478638\n",
      "Inner Loss:  3.0930447578430176\n",
      "Inner Loss:  1.714435875415802\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 10  9]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.386789560317993\n",
      "Inner Loss:  3.2439496517181396\n",
      "Inner Loss:  1.7297714948654175\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11  7 12]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.584397792816162\n",
      "Inner Loss:  2.786603093147278\n",
      "Inner Loss:  1.6215863227844238\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 11 10]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.864988565444946\n",
      "Inner Loss:  2.9419578313827515\n",
      "Inner Loss:  1.5906607508659363\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 10 11]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.397578001022339\n",
      "Inner Loss:  3.24463152885437\n",
      "Inner Loss:  1.7084718346595764\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13 12  5]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.350234031677246\n",
      "Inner Loss:  2.681578516960144\n",
      "Inner Loss:  1.6194932460784912\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10  9 11]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.083693504333496\n",
      "Inner Loss:  3.03933846950531\n",
      "Inner Loss:  1.5752725005149841\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 6 15  9]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.267399787902832\n",
      "Inner Loss:  3.1120957136154175\n",
      "Inner Loss:  1.5302125811576843\n",
      "[[ 4  1  1]\n",
      " [ 0  0  0]\n",
      " [14  6  4]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.798357725143433\n",
      "Inner Loss:  2.820470690727234\n",
      "Inner Loss:  1.4686887860298157\n",
      "[[ 1  0  0]\n",
      " [ 0  0  0]\n",
      " [11  8 10]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.853708505630493\n",
      "Inner Loss:  2.9176087379455566\n",
      "Inner Loss:  1.538537621498108\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 14  8]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.837764501571655\n",
      "Inner Loss:  3.343199849128723\n",
      "Inner Loss:  1.3730457425117493\n",
      "[[ 7  8 15]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  5.038534164428711\n",
      "Inner Loss:  2.9825925827026367\n",
      "Inner Loss:  1.7486637234687805\n",
      "[[ 0  0  0]\n",
      " [ 1  0  0]\n",
      " [14  8  7]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.929191827774048\n",
      "Inner Loss:  2.904794216156006\n",
      "Inner Loss:  1.5312455892562866\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 15  8]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.142239093780518\n",
      "Inner Loss:  3.0606378316879272\n",
      "Inner Loss:  1.7844637632369995\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11  7 12]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.992089748382568\n",
      "Inner Loss:  2.941649913787842\n",
      "Inner Loss:  1.3106319904327393\n",
      "[[12  9  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.835662603378296\n",
      "Inner Loss:  2.8880434036254883\n",
      "Inner Loss:  1.7827121019363403\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 13  9]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.869929790496826\n",
      "Inner Loss:  2.9361170530319214\n",
      "Inner Loss:  1.6594926714897156\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7  9 14]]\n",
      "Step: 20 \ttraining Acc: 0.32333333333333336\n",
      "\n",
      "-----------------Testing Mode-----------------\n",
      "\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.388765096664429\n",
      "Inner Loss:  3.196950078010559\n",
      "Inner Loss:  1.2851935625076294\n",
      "Inner Loss:  2.0851523876190186\n",
      "Inner Loss:  1.428070843219757\n",
      "Inner Loss:  1.2092360854148865\n",
      "Inner Loss:  1.115246295928955\n",
      "Inner Loss:  1.0948788523674011\n",
      "Inner Loss:  1.092958152294159\n",
      "Inner Loss:  1.0952323079109192\n",
      "[[ 5  9 14]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.8724647760391235\n",
      "Inner Loss:  2.9595483541488647\n",
      "Inner Loss:  1.4585888385772705\n",
      "Inner Loss:  1.245719075202942\n",
      "Inner Loss:  1.1283274292945862\n",
      "Inner Loss:  1.130970060825348\n",
      "Inner Loss:  1.1200459003448486\n",
      "Inner Loss:  1.1058804988861084\n",
      "Inner Loss:  1.1083813905715942\n",
      "Inner Loss:  1.1161667704582214\n",
      "[[2 2 9]\n",
      " [5 4 5]\n",
      " [0 2 1]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.176903963088989\n",
      "Inner Loss:  2.677390694618225\n",
      "Inner Loss:  1.6434451937675476\n",
      "Inner Loss:  1.171230673789978\n",
      "Inner Loss:  1.1301182508468628\n",
      "Inner Loss:  1.0835506319999695\n",
      "Inner Loss:  1.0930944085121155\n",
      "Inner Loss:  1.090524971485138\n",
      "Inner Loss:  1.1157729625701904\n",
      "Inner Loss:  1.100289523601532\n",
      "[[ 0  0  0]\n",
      " [ 9 11 10]\n",
      " [ 0  0  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.433981418609619\n",
      "Inner Loss:  2.8162171840667725\n",
      "Inner Loss:  1.636612057685852\n",
      "Inner Loss:  1.177952766418457\n",
      "Inner Loss:  1.1951887011528015\n",
      "Inner Loss:  1.1215131282806396\n",
      "Inner Loss:  1.0994928479194641\n",
      "Inner Loss:  1.0944533348083496\n",
      "Inner Loss:  1.112219512462616\n",
      "Inner Loss:  1.1038711071014404\n",
      "[[0 1 1]\n",
      " [5 9 7]\n",
      " [2 4 1]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.77939772605896\n",
      "Inner Loss:  3.0032678842544556\n",
      "Inner Loss:  1.5460033416748047\n",
      "Inner Loss:  1.229759693145752\n",
      "Inner Loss:  1.123730480670929\n",
      "Inner Loss:  1.0971670150756836\n",
      "Inner Loss:  1.1146957278251648\n",
      "Inner Loss:  1.0970304012298584\n",
      "Inner Loss:  1.0847494006156921\n",
      "Inner Loss:  1.094745397567749\n",
      "[[ 2  1  1]\n",
      " [10  5  7]\n",
      " [ 0  2  2]]\n",
      "Step: 20 Test F1: 0.2866666666666667\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.742839336395264\n",
      "Inner Loss:  3.33993923664093\n",
      "Inner Loss:  2.502255856990814\n",
      "[[ 0  0  0]\n",
      " [ 6 14 10]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.540860176086426\n",
      "Inner Loss:  3.2421122789382935\n",
      "Inner Loss:  2.099670946598053\n",
      "[[ 0  0  0]\n",
      " [ 8 12 10]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.838419198989868\n",
      "Inner Loss:  2.9346282482147217\n",
      "Inner Loss:  1.409330427646637\n",
      "[[8 9 9]\n",
      " [3 1 0]\n",
      " [0 0 0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.799863696098328\n",
      "Inner Loss:  2.928123354911804\n",
      "Inner Loss:  1.495404064655304\n",
      "[[1 3 5]\n",
      " [4 4 2]\n",
      " [4 5 2]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.680145502090454\n",
      "Inner Loss:  2.8603581190109253\n",
      "Inner Loss:  1.4456338286399841\n",
      "[[7 5 3]\n",
      " [2 1 4]\n",
      " [2 4 2]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.632085919380188\n",
      "Inner Loss:  2.8644944429397583\n",
      "Inner Loss:  1.4268277883529663\n",
      "[[ 5  4 12]\n",
      " [ 1  0  1]\n",
      " [ 2  3  2]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.096312522888184\n",
      "Inner Loss:  2.6115833520889282\n",
      "Inner Loss:  1.4301881790161133\n",
      "[[0 0 0]\n",
      " [4 1 2]\n",
      " [6 9 8]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.8289512395858765\n",
      "Inner Loss:  2.435372829437256\n",
      "Inner Loss:  1.5273157358169556\n",
      "[[0 0 0]\n",
      " [2 3 4]\n",
      " [9 6 6]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.359604358673096\n",
      "Inner Loss:  3.1716238260269165\n",
      "Inner Loss:  2.4023512601852417\n",
      "[[ 6 13  7]\n",
      " [ 1  0  3]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.770384073257446\n",
      "Inner Loss:  2.92487370967865\n",
      "Inner Loss:  1.3190820813179016\n",
      "[[ 7 12  9]\n",
      " [ 0  1  1]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.04135537147522\n",
      "Inner Loss:  3.10174822807312\n",
      "Inner Loss:  1.597610592842102\n",
      "[[0 2 1]\n",
      " [5 3 4]\n",
      " [4 6 5]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.697740316390991\n",
      "Inner Loss:  2.8086349964141846\n",
      "Inner Loss:  2.692465841770172\n",
      "[[ 8 12 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.268263101577759\n",
      "Inner Loss:  2.6669117212295532\n",
      "Inner Loss:  1.4275489449501038\n",
      "[[ 1  1  1]\n",
      " [ 1  2  2]\n",
      " [10  3  9]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.918759107589722\n",
      "Inner Loss:  3.021454691886902\n",
      "Inner Loss:  1.500956118106842\n",
      "[[ 9  8 11]\n",
      " [ 0  0  0]\n",
      " [ 1  1  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.704436540603638\n",
      "Inner Loss:  2.866831064224243\n",
      "Inner Loss:  1.346883475780487\n",
      "[[12  9  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.470589637756348\n",
      "Inner Loss:  2.8073477745056152\n",
      "Inner Loss:  1.5286210775375366\n",
      "[[0 0 0]\n",
      " [3 6 4]\n",
      " [4 6 7]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.42023491859436\n",
      "Inner Loss:  2.7881410121917725\n",
      "Inner Loss:  1.4407696723937988\n",
      "[[0 1 1]\n",
      " [5 0 4]\n",
      " [8 5 6]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.780134439468384\n",
      "Inner Loss:  2.8671923875808716\n",
      "Inner Loss:  1.3500701189041138\n",
      "[[ 0  0  0]\n",
      " [ 8 12 10]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.407860994338989\n",
      "Inner Loss:  2.6384012699127197\n",
      "Inner Loss:  1.2918164134025574\n",
      "[[11  9  5]\n",
      " [ 0  1  1]\n",
      " [ 2  0  1]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.655220985412598\n",
      "Inner Loss:  2.8187021017074585\n",
      "Inner Loss:  1.3219234347343445\n",
      "[[12  8  7]\n",
      " [ 1  0  0]\n",
      " [ 2  0  0]]\n",
      "Step: 21 \ttraining Acc: 0.32666666666666677\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.860365867614746\n",
      "Inner Loss:  2.542507767677307\n",
      "Inner Loss:  1.1862802505493164\n",
      "[[ 3 15 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.707993268966675\n",
      "Inner Loss:  2.9808290004730225\n",
      "Inner Loss:  1.2823646664619446\n",
      "[[11  9 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.863980531692505\n",
      "Inner Loss:  2.9069364070892334\n",
      "Inner Loss:  1.1552727222442627\n",
      "[[ 6 15  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.1467649936676025\n",
      "Inner Loss:  2.5915520191192627\n",
      "Inner Loss:  1.1306129097938538\n",
      "[[ 8 12 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.145431995391846\n",
      "Inner Loss:  3.090977668762207\n",
      "Inner Loss:  1.122237503528595\n",
      "[[12 10  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.38460111618042\n",
      "Inner Loss:  2.590805768966675\n",
      "Inner Loss:  1.1145016551017761\n",
      "[[ 7 10 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.861032247543335\n",
      "Inner Loss:  2.9125152826309204\n",
      "Inner Loss:  1.1657491326332092\n",
      "[[12  9  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.293789625167847\n",
      "Inner Loss:  2.741337776184082\n",
      "Inner Loss:  1.2170502543449402\n",
      "[[13  8  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.831216335296631\n",
      "Inner Loss:  2.542955756187439\n",
      "Inner Loss:  1.2361881136894226\n",
      "[[10  9 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.9390530586242676\n",
      "Inner Loss:  2.428990364074707\n",
      "Inner Loss:  1.0847076773643494\n",
      "[[13 10  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.1566115617752075\n",
      "Inner Loss:  2.752888321876526\n",
      "Inner Loss:  1.2920352816581726\n",
      "[[ 6 10 13]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.24543309211731\n",
      "Inner Loss:  2.692704916000366\n",
      "Inner Loss:  1.2468329668045044\n",
      "[[ 5 14 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.633412718772888\n",
      "Inner Loss:  2.815164089202881\n",
      "Inner Loss:  1.1783287525177002\n",
      "[[11 15  4]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.443486928939819\n",
      "Inner Loss:  2.7823824882507324\n",
      "Inner Loss:  1.1907638907432556\n",
      "[[12 12  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.7852959632873535\n",
      "Inner Loss:  2.488492727279663\n",
      "Inner Loss:  1.25033837556839\n",
      "[[ 8 13  7]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.15543007850647\n",
      "Inner Loss:  2.5987327098846436\n",
      "Inner Loss:  1.1549734473228455\n",
      "[[12  5 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.323113322257996\n",
      "Inner Loss:  2.758467197418213\n",
      "Inner Loss:  1.3145052790641785\n",
      "[[10  9 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.8829821348190308\n",
      "Inner Loss:  2.5842432975769043\n",
      "Inner Loss:  1.2961153388023376\n",
      "[[ 9  6 15]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.303301215171814\n",
      "Inner Loss:  2.606781244277954\n",
      "Inner Loss:  1.11334890127182\n",
      "[[ 8  9 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.490169525146484\n",
      "Inner Loss:  2.8507707118988037\n",
      "Inner Loss:  1.3235024213790894\n",
      "[[ 4  7 13]\n",
      " [ 3  2  1]\n",
      " [ 0  0  0]]\n",
      "Step: 22 \ttraining Acc: 0.305\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.076756477355957\n",
      "Inner Loss:  2.648403286933899\n",
      "Inner Loss:  1.2224023938179016\n",
      "[[11  5 10]\n",
      " [ 0  3  1]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.5243546962738037\n",
      "Inner Loss:  2.2771719694137573\n",
      "Inner Loss:  1.152708649635315\n",
      "[[ 9  9 10]\n",
      " [ 0  0  2]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.146017789840698\n",
      "Inner Loss:  2.5254392623901367\n",
      "Inner Loss:  1.1563323736190796\n",
      "[[10  9 10]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.969263792037964\n",
      "Inner Loss:  2.510908603668213\n",
      "Inner Loss:  1.1477589011192322\n",
      "[[13  9  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.515679121017456\n",
      "Inner Loss:  2.6427109241485596\n",
      "Inner Loss:  1.1028408408164978\n",
      "[[10 12  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.5220348834991455\n",
      "Inner Loss:  2.773701548576355\n",
      "Inner Loss:  1.1696392893791199\n",
      "[[ 7 12 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.709284782409668\n",
      "Inner Loss:  2.2977980375289917\n",
      "Inner Loss:  1.144091784954071\n",
      "[[12 12  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.118243455886841\n",
      "Inner Loss:  2.5139098167419434\n",
      "Inner Loss:  1.1233325004577637\n",
      "[[12 11  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.5942583084106445\n",
      "Inner Loss:  2.7662945985794067\n",
      "Inner Loss:  1.1265579462051392\n",
      "[[ 8 15  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.491284132003784\n",
      "Inner Loss:  2.6695128679275513\n",
      "Inner Loss:  1.097115933895111\n",
      "[[ 9 12  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.082934498786926\n",
      "Inner Loss:  2.6681162118911743\n",
      "Inner Loss:  1.2435206174850464\n",
      "[[10  9 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.183649063110352\n",
      "Inner Loss:  2.556503653526306\n",
      "Inner Loss:  1.135542392730713\n",
      "[[10 11  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.193206191062927\n",
      "Inner Loss:  2.5013009309768677\n",
      "Inner Loss:  1.1424800157546997\n",
      "[[ 6 12 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.410228252410889\n",
      "Inner Loss:  2.6630706787109375\n",
      "Inner Loss:  1.1094791293144226\n",
      "[[ 9 10 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.102140665054321\n",
      "Inner Loss:  2.548392415046692\n",
      "Inner Loss:  1.1755765080451965\n",
      "[[ 9  8 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.626348376274109\n",
      "Inner Loss:  2.734358310699463\n",
      "Inner Loss:  1.136512279510498\n",
      "[[ 9 11 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.4551842212677\n",
      "Inner Loss:  2.723539352416992\n",
      "Inner Loss:  1.1475535035133362\n",
      "[[ 8 13  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.5128694772720337\n",
      "Inner Loss:  2.175599992275238\n",
      "Inner Loss:  1.0875611305236816\n",
      "[[14  7  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.4366332292556763\n",
      "Inner Loss:  2.279488205909729\n",
      "Inner Loss:  1.1433591842651367\n",
      "[[11  7  9]\n",
      " [ 1  1  1]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.415965437889099\n",
      "Inner Loss:  2.694641947746277\n",
      "Inner Loss:  1.1412729620933533\n",
      "[[13 10  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "Step: 23 \ttraining Acc: 0.34\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.776333808898926\n",
      "Inner Loss:  3.3156120777130127\n",
      "Inner Loss:  1.7381162643432617\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [10 10  9]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.415658473968506\n",
      "Inner Loss:  3.669474482536316\n",
      "Inner Loss:  1.823935627937317\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [16  3 11]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.966939210891724\n",
      "Inner Loss:  3.456444501876831\n",
      "Inner Loss:  1.8323705196380615\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [14  6 10]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.777092695236206\n",
      "Inner Loss:  3.334024429321289\n",
      "Inner Loss:  1.7709433436393738\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  9  9]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.530187606811523\n",
      "Inner Loss:  3.1576062440872192\n",
      "Inner Loss:  1.720359444618225\n",
      "[[ 0  0  0]\n",
      " [ 1  0  1]\n",
      " [ 9 10  9]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.137717008590698\n",
      "Inner Loss:  2.9548568725585938\n",
      "Inner Loss:  1.6646373271942139\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13 10  7]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.3792884349823\n",
      "Inner Loss:  3.104427218437195\n",
      "Inner Loss:  1.7318865060806274\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 11 10]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.024626016616821\n",
      "Inner Loss:  3.494525671005249\n",
      "Inner Loss:  1.8111704587936401\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8  8 14]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  5.189435958862305\n",
      "Inner Loss:  3.5282466411590576\n",
      "Inner Loss:  1.839345932006836\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 10 10]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.511933922767639\n",
      "Inner Loss:  3.1408963203430176\n",
      "Inner Loss:  1.7317311763763428\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [11  8 10]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.8437745571136475\n",
      "Inner Loss:  3.311210870742798\n",
      "Inner Loss:  1.735636830329895\n",
      "[[ 0  0  0]\n",
      " [ 1  0  2]\n",
      " [ 7  9 11]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.733713626861572\n",
      "Inner Loss:  3.289994478225708\n",
      "Inner Loss:  1.7913700938224792\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 10  9]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.858153820037842\n",
      "Inner Loss:  2.8167937994003296\n",
      "Inner Loss:  1.6563698053359985\n",
      "[[0 0 0]\n",
      " [5 4 5]\n",
      " [5 3 8]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.543450832366943\n",
      "Inner Loss:  3.1933573484420776\n",
      "Inner Loss:  1.7754518389701843\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 10  9]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.648265361785889\n",
      "Inner Loss:  3.2247291803359985\n",
      "Inner Loss:  1.723830223083496\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11  8 11]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.255404949188232\n",
      "Inner Loss:  3.036314606666565\n",
      "Inner Loss:  1.6944035291671753\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9  9 12]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.918100595474243\n",
      "Inner Loss:  2.789826273918152\n",
      "Inner Loss:  1.6154984831809998\n",
      "[[0 0 0]\n",
      " [4 5 0]\n",
      " [8 5 8]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.550088882446289\n",
      "Inner Loss:  3.2039040327072144\n",
      "Inner Loss:  1.8042412996292114\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 11 10]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.928785800933838\n",
      "Inner Loss:  2.818537473678589\n",
      "Inner Loss:  1.5931891798973083\n",
      "[[0 0 0]\n",
      " [4 2 4]\n",
      " [5 7 8]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.913493871688843\n",
      "Inner Loss:  3.3226398229599\n",
      "Inner Loss:  1.7399783730506897\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 5 15 10]]\n",
      "Step: 24 \ttraining Acc: 0.3466666666666666\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.664537191390991\n",
      "Inner Loss:  3.361897826194763\n",
      "Inner Loss:  1.9624727368354797\n",
      "[[0 0 0]\n",
      " [1 2 2]\n",
      " [9 9 7]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.757612228393555\n",
      "Inner Loss:  4.074878692626953\n",
      "Inner Loss:  2.3953468799591064\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12 14  4]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.109864354133606\n",
      "Inner Loss:  3.0234874486923218\n",
      "Inner Loss:  2.019124925136566\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [ 9  6 14]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.8835649490356445\n",
      "Inner Loss:  3.53243350982666\n",
      "Inner Loss:  2.2321081161499023\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 12  8]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.361904144287109\n",
      "Inner Loss:  3.860290765762329\n",
      "Inner Loss:  2.3247228860855103\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 12 11]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.759563088417053\n",
      "Inner Loss:  3.4707539081573486\n",
      "Inner Loss:  2.225718855857849\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9  8 13]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.398731231689453\n",
      "Inner Loss:  3.808194637298584\n",
      "Inner Loss:  2.1314024925231934\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [10  9 10]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.1468117237091064\n",
      "Inner Loss:  3.649634003639221\n",
      "Inner Loss:  2.1937283873558044\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 10  9]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.489159345626831\n",
      "Inner Loss:  3.240325450897217\n",
      "Inner Loss:  2.084577977657318\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  9  9]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.619020938873291\n",
      "Inner Loss:  3.9974868297576904\n",
      "Inner Loss:  2.29849636554718\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9  7 14]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.640249729156494\n",
      "Inner Loss:  3.3464465141296387\n",
      "Inner Loss:  2.180536210536957\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11  8 11]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.6502448320388794\n",
      "Inner Loss:  2.6854324340820312\n",
      "Inner Loss:  1.9141596555709839\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [ 8 10 11]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.279884219169617\n",
      "Inner Loss:  3.15376877784729\n",
      "Inner Loss:  2.1147431135177612\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [12  9  8]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.333248496055603\n",
      "Inner Loss:  3.179396390914917\n",
      "Inner Loss:  2.103628993034363\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10 10 10]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.556952476501465\n",
      "Inner Loss:  3.2923663854599\n",
      "Inner Loss:  2.043748199939728\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10  9 11]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.189618349075317\n",
      "Inner Loss:  3.7051819562911987\n",
      "Inner Loss:  2.21612548828125\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13  7 10]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.9070329666137695\n",
      "Inner Loss:  3.5781525373458862\n",
      "Inner Loss:  2.1956146955490112\n",
      "[[ 0  0  0]\n",
      " [ 1  0  1]\n",
      " [10 13  5]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.866575717926025\n",
      "Inner Loss:  3.4811339378356934\n",
      "Inner Loss:  2.1680349111557007\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13  8  9]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.5860137939453125\n",
      "Inner Loss:  3.346889615058899\n",
      "Inner Loss:  2.142314612865448\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [ 9  6 14]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.565422892570496\n",
      "Inner Loss:  3.2998769283294678\n",
      "Inner Loss:  2.12416934967041\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11 12  7]]\n",
      "Step: 0 \ttraining Acc: 0.33666666666666667\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.982026815414429\n",
      "Inner Loss:  3.4247677326202393\n",
      "Inner Loss:  2.1790846586227417\n",
      "[[ 0  0  0]\n",
      " [ 5  7 12]\n",
      " [ 1  4  1]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.562108278274536\n",
      "Inner Loss:  3.1607885360717773\n",
      "Inner Loss:  2.1045541167259216\n",
      "[[0 0 0]\n",
      " [9 7 9]\n",
      " [2 0 3]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  5.101686239242554\n",
      "Inner Loss:  3.567139148712158\n",
      "Inner Loss:  2.159149646759033\n",
      "[[0 0 0]\n",
      " [7 4 8]\n",
      " [3 4 4]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.722143650054932\n",
      "Inner Loss:  3.8687974214553833\n",
      "Inner Loss:  2.244616985321045\n",
      "[[0 0 0]\n",
      " [4 4 9]\n",
      " [5 5 3]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.203627109527588\n",
      "Inner Loss:  3.5863624811172485\n",
      "Inner Loss:  2.207526922225952\n",
      "[[ 0  0  0]\n",
      " [10  4  5]\n",
      " [ 3  5  3]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.212615966796875\n",
      "Inner Loss:  3.6208611726760864\n",
      "Inner Loss:  2.193777322769165\n",
      "[[0 0 0]\n",
      " [4 8 4]\n",
      " [7 3 4]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  5.227645397186279\n",
      "Inner Loss:  3.610572099685669\n",
      "Inner Loss:  2.215472102165222\n",
      "[[ 0  0  0]\n",
      " [12  8  2]\n",
      " [ 1  5  2]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  5.598245859146118\n",
      "Inner Loss:  3.682315468788147\n",
      "Inner Loss:  2.30008727312088\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7 13 10]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.777055025100708\n",
      "Inner Loss:  3.304535150527954\n",
      "Inner Loss:  2.1375824213027954\n",
      "[[0 0 0]\n",
      " [5 8 7]\n",
      " [3 4 3]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.167915344238281\n",
      "Inner Loss:  3.57170832157135\n",
      "Inner Loss:  2.1878263354301453\n",
      "[[0 0 0]\n",
      " [8 6 8]\n",
      " [1 1 6]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.23228907585144\n",
      "Inner Loss:  3.58447265625\n",
      "Inner Loss:  2.156558096408844\n",
      "[[0 0 0]\n",
      " [5 6 9]\n",
      " [3 4 3]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  5.1434550285339355\n",
      "Inner Loss:  3.60818350315094\n",
      "Inner Loss:  2.2343920469284058\n",
      "[[0 0 0]\n",
      " [5 2 6]\n",
      " [7 8 2]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.745794177055359\n",
      "Inner Loss:  3.3172487020492554\n",
      "Inner Loss:  2.155033528804779\n",
      "[[ 0  0  0]\n",
      " [11  9  6]\n",
      " [ 2  2  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.487047553062439\n",
      "Inner Loss:  3.1027796268463135\n",
      "Inner Loss:  2.0838531851768494\n",
      "[[0 0 0]\n",
      " [8 6 9]\n",
      " [2 3 2]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  6.126163482666016\n",
      "Inner Loss:  4.130511045455933\n",
      "Inner Loss:  2.334313154220581\n",
      "[[ 0  0  0]\n",
      " [ 1  0  0]\n",
      " [10  8 11]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.774048566818237\n",
      "Inner Loss:  3.911875367164612\n",
      "Inner Loss:  2.2492101192474365\n",
      "[[0 0 0]\n",
      " [4 4 3]\n",
      " [6 6 7]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.974930763244629\n",
      "Inner Loss:  4.056722044944763\n",
      "Inner Loss:  2.255726993083954\n",
      "[[0 0 0]\n",
      " [2 3 2]\n",
      " [9 8 6]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.213448762893677\n",
      "Inner Loss:  3.6039522886276245\n",
      "Inner Loss:  2.181200325489044\n",
      "[[0 0 0]\n",
      " [8 5 6]\n",
      " [4 5 2]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.612154960632324\n",
      "Inner Loss:  3.838207721710205\n",
      "Inner Loss:  2.250859260559082\n",
      "[[0 0 0]\n",
      " [6 1 5]\n",
      " [5 5 8]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.017470836639404\n",
      "Inner Loss:  3.433570623397827\n",
      "Inner Loss:  2.218391716480255\n",
      "[[0 0 0]\n",
      " [9 7 5]\n",
      " [3 5 1]]\n",
      "Step: 1 \ttraining Acc: 0.3\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.999161958694458\n",
      "Inner Loss:  3.1700828075408936\n",
      "Inner Loss:  1.7989432215690613\n",
      "[[ 0  0  0]\n",
      " [ 9 11  5]\n",
      " [ 0  0  5]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  5.016895771026611\n",
      "Inner Loss:  3.1754907369613647\n",
      "Inner Loss:  1.7953070402145386\n",
      "[[ 0  0  0]\n",
      " [12  9  7]\n",
      " [ 0  1  1]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.751474380493164\n",
      "Inner Loss:  3.0408809185028076\n",
      "Inner Loss:  1.782791018486023\n",
      "[[0 0 0]\n",
      " [9 9 6]\n",
      " [1 2 3]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.428009033203125\n",
      "Inner Loss:  3.321333885192871\n",
      "Inner Loss:  1.9066241383552551\n",
      "[[ 0  0  0]\n",
      " [ 2  5  1]\n",
      " [ 1 10 11]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  5.866383075714111\n",
      "Inner Loss:  3.6821086406707764\n",
      "Inner Loss:  1.8907098770141602\n",
      "[[0 0 0]\n",
      " [2 7 5]\n",
      " [6 3 7]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  5.59738302230835\n",
      "Inner Loss:  3.5186737775802612\n",
      "Inner Loss:  1.9018767476081848\n",
      "[[ 0  0  0]\n",
      " [ 7 11  7]\n",
      " [ 2  2  1]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.983400344848633\n",
      "Inner Loss:  3.205079436302185\n",
      "Inner Loss:  1.85684734582901\n",
      "[[ 0  0  0]\n",
      " [11 10  6]\n",
      " [ 1  1  1]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.851212739944458\n",
      "Inner Loss:  3.0680463314056396\n",
      "Inner Loss:  1.816343605518341\n",
      "[[ 0  0  0]\n",
      " [ 3 11  6]\n",
      " [ 2  2  6]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.747878074645996\n",
      "Inner Loss:  3.087198853492737\n",
      "Inner Loss:  1.8432336449623108\n",
      "[[ 0  0  0]\n",
      " [11  9  8]\n",
      " [ 1  0  1]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.707273721694946\n",
      "Inner Loss:  3.537410855293274\n",
      "Inner Loss:  1.8760876059532166\n",
      "[[0 0 0]\n",
      " [5 4 4]\n",
      " [5 6 6]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.634144306182861\n",
      "Inner Loss:  2.908253312110901\n",
      "Inner Loss:  1.816758155822754\n",
      "[[ 0  0  0]\n",
      " [14  8  4]\n",
      " [ 2  2  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.7136101722717285\n",
      "Inner Loss:  3.0140823125839233\n",
      "Inner Loss:  1.8104282021522522\n",
      "[[ 0  0  0]\n",
      " [ 9 11  9]\n",
      " [ 0  0  1]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  5.797800779342651\n",
      "Inner Loss:  3.5954266786575317\n",
      "Inner Loss:  1.9309797883033752\n",
      "[[0 0 0]\n",
      " [1 5 1]\n",
      " [8 6 9]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.415771961212158\n",
      "Inner Loss:  3.3676323890686035\n",
      "Inner Loss:  1.8928454518318176\n",
      "[[ 0  0  0]\n",
      " [ 5 12  4]\n",
      " [ 2  2  5]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.441165328025818\n",
      "Inner Loss:  2.8842055797576904\n",
      "Inner Loss:  1.7935996651649475\n",
      "[[ 0  0  0]\n",
      " [11 10  9]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.054269075393677\n",
      "Inner Loss:  3.202880024909973\n",
      "Inner Loss:  1.8578161001205444\n",
      "[[ 0  0  0]\n",
      " [ 6  5 10]\n",
      " [ 3  2  4]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.633727788925171\n",
      "Inner Loss:  3.0246102809906006\n",
      "Inner Loss:  1.8157539367675781\n",
      "[[ 0  0  0]\n",
      " [11 11  8]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.908529996871948\n",
      "Inner Loss:  3.083092212677002\n",
      "Inner Loss:  1.8468453288078308\n",
      "[[ 0  0  0]\n",
      " [ 6 10  7]\n",
      " [ 2  5  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  5.255335569381714\n",
      "Inner Loss:  3.294333577156067\n",
      "Inner Loss:  1.861074984073639\n",
      "[[ 0  0  0]\n",
      " [ 6 11  2]\n",
      " [ 3  5  3]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.535253524780273\n",
      "Inner Loss:  2.94097101688385\n",
      "Inner Loss:  1.8181517124176025\n",
      "[[ 0  0  0]\n",
      " [ 8  6 14]\n",
      " [ 1  1  0]]\n",
      "Step: 2 \ttraining Acc: 0.3983333333333333\n",
      "----Task 0 ----\n",
      "Inner Loss:  5.339025497436523\n",
      "Inner Loss:  2.948864698410034\n",
      "Inner Loss:  1.3115612268447876\n",
      "[[11 12  6]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.671810626983643\n",
      "Inner Loss:  2.6253689527511597\n",
      "Inner Loss:  1.3387854099273682\n",
      "[[ 0  1  0]\n",
      " [ 7  7 13]\n",
      " [ 1  1  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.672365665435791\n",
      "Inner Loss:  2.6446280479431152\n",
      "Inner Loss:  1.3237586617469788\n",
      "[[4 4 9]\n",
      " [4 5 4]\n",
      " [0 0 0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  5.346033334732056\n",
      "Inner Loss:  2.9036765098571777\n",
      "Inner Loss:  1.32087904214859\n",
      "[[ 7 10  3]\n",
      " [ 4  1  2]\n",
      " [ 1  0  2]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.004998445510864\n",
      "Inner Loss:  2.276242971420288\n",
      "Inner Loss:  1.4138096570968628\n",
      "[[ 0  0  0]\n",
      " [ 8 10 10]\n",
      " [ 2  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.79661750793457\n",
      "Inner Loss:  2.6956790685653687\n",
      "Inner Loss:  1.2599433660507202\n",
      "[[ 6  5 10]\n",
      " [ 2  3  4]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.579116344451904\n",
      "Inner Loss:  2.583135962486267\n",
      "Inner Loss:  1.4167507886886597\n",
      "[[ 0  0  0]\n",
      " [10  9 10]\n",
      " [ 0  0  1]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.793642520904541\n",
      "Inner Loss:  2.64973783493042\n",
      "Inner Loss:  1.4005022048950195\n",
      "[[0 0 0]\n",
      " [3 5 6]\n",
      " [2 6 8]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.144531965255737\n",
      "Inner Loss:  2.373565375804901\n",
      "Inner Loss:  1.3793681859970093\n",
      "[[ 0  0  0]\n",
      " [ 9  5 15]\n",
      " [ 0  1  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  5.494153022766113\n",
      "Inner Loss:  3.0111559629440308\n",
      "Inner Loss:  1.2617878913879395\n",
      "[[16  4 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  5.177237510681152\n",
      "Inner Loss:  2.8850373029708862\n",
      "Inner Loss:  1.384251356124878\n",
      "[[5 5 7]\n",
      " [1 4 5]\n",
      " [1 0 2]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.357568621635437\n",
      "Inner Loss:  2.511149764060974\n",
      "Inner Loss:  1.3926021456718445\n",
      "[[ 0  0  0]\n",
      " [ 9 14  6]\n",
      " [ 1  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.317962288856506\n",
      "Inner Loss:  2.5294302701950073\n",
      "Inner Loss:  1.4318154454231262\n",
      "[[ 0  0  0]\n",
      " [ 4 13 13]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  5.244364261627197\n",
      "Inner Loss:  2.8611338138580322\n",
      "Inner Loss:  1.3921290636062622\n",
      "[[ 1  0  1]\n",
      " [ 1  2  2]\n",
      " [10  5  8]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.711673974990845\n",
      "Inner Loss:  2.6919004917144775\n",
      "Inner Loss:  1.3021604418754578\n",
      "[[4 6 8]\n",
      " [5 2 5]\n",
      " [0 0 0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.269436597824097\n",
      "Inner Loss:  2.9206594228744507\n",
      "Inner Loss:  1.2914706468582153\n",
      "[[10  7 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.11614727973938\n",
      "Inner Loss:  2.8440617322921753\n",
      "Inner Loss:  1.2580382227897644\n",
      "[[10 10  7]\n",
      " [ 2  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  5.088977813720703\n",
      "Inner Loss:  2.814341187477112\n",
      "Inner Loss:  1.3497802019119263\n",
      "[[ 0  1  0]\n",
      " [ 8 10  4]\n",
      " [ 1  4  2]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.752176284790039\n",
      "Inner Loss:  2.682189464569092\n",
      "Inner Loss:  1.403894066810608\n",
      "[[ 0  0  0]\n",
      " [10  8  8]\n",
      " [ 2  0  2]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  5.170848608016968\n",
      "Inner Loss:  2.897240996360779\n",
      "Inner Loss:  1.287354826927185\n",
      "[[ 5 11 13]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "Step: 3 \ttraining Acc: 0.33999999999999997\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.159176230430603\n",
      "Inner Loss:  2.112754464149475\n",
      "Inner Loss:  1.1137660145759583\n",
      "[[ 8 16  4]\n",
      " [ 1  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.503820419311523\n",
      "Inner Loss:  2.2060710191726685\n",
      "Inner Loss:  1.1246948838233948\n",
      "[[10  8 11]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.836127519607544\n",
      "Inner Loss:  2.294655442237854\n",
      "Inner Loss:  1.091665267944336\n",
      "[[ 5 16  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.532428741455078\n",
      "Inner Loss:  2.205910325050354\n",
      "Inner Loss:  1.0864307284355164\n",
      "[[14  8  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.333399176597595\n",
      "Inner Loss:  2.1711432933807373\n",
      "Inner Loss:  1.122394323348999\n",
      "[[5 8 5]\n",
      " [3 5 4]\n",
      " [0 0 0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.684925556182861\n",
      "Inner Loss:  2.3052010536193848\n",
      "Inner Loss:  1.0846075415611267\n",
      "[[10 11  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.148000001907349\n",
      "Inner Loss:  2.117616593837738\n",
      "Inner Loss:  1.1276085376739502\n",
      "[[6 9 9]\n",
      " [1 2 3]\n",
      " [0 0 0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.293088912963867\n",
      "Inner Loss:  2.1700294613838196\n",
      "Inner Loss:  1.11983984708786\n",
      "[[14  4 10]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  4.080999493598938\n",
      "Inner Loss:  2.124836266040802\n",
      "Inner Loss:  1.163277268409729\n",
      "[[5 4 9]\n",
      " [2 6 4]\n",
      " [0 0 0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.776268243789673\n",
      "Inner Loss:  2.32640278339386\n",
      "Inner Loss:  1.0999032258987427\n",
      "[[11 11  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.741469860076904\n",
      "Inner Loss:  2.2833627462387085\n",
      "Inner Loss:  1.1524949073791504\n",
      "[[ 5 10 15]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.98347806930542\n",
      "Inner Loss:  2.3583165407180786\n",
      "Inner Loss:  1.0725756287574768\n",
      "[[ 8 16  6]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  4.875898122787476\n",
      "Inner Loss:  2.355987548828125\n",
      "Inner Loss:  1.1071916818618774\n",
      "[[ 7 10 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.526005506515503\n",
      "Inner Loss:  2.2144047021865845\n",
      "Inner Loss:  1.109849989414215\n",
      "[[ 8  8 13]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.329398155212402\n",
      "Inner Loss:  2.1871429681777954\n",
      "Inner Loss:  1.1121243834495544\n",
      "[[12  5 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  5.023528337478638\n",
      "Inner Loss:  2.369042992591858\n",
      "Inner Loss:  1.0778954029083252\n",
      "[[ 8  6 15]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  5.395221710205078\n",
      "Inner Loss:  2.4621310234069824\n",
      "Inner Loss:  1.1003409624099731\n",
      "[[14  4 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.293903112411499\n",
      "Inner Loss:  2.1261138916015625\n",
      "Inner Loss:  1.1002792119979858\n",
      "[[ 7 12 10]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.399721741676331\n",
      "Inner Loss:  2.2062877416610718\n",
      "Inner Loss:  1.1107730865478516\n",
      "[[ 7 12 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  4.979814529418945\n",
      "Inner Loss:  2.3487250804901123\n",
      "Inner Loss:  1.1030471324920654\n",
      "[[13  5 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "Step: 4 \ttraining Acc: 0.31833333333333336\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.265319347381592\n",
      "Inner Loss:  1.9753516912460327\n",
      "Inner Loss:  1.1089335083961487\n",
      "[[13  5 11]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.6745487451553345\n",
      "Inner Loss:  1.782008409500122\n",
      "Inner Loss:  1.094955325126648\n",
      "[[12  8  7]\n",
      " [ 1  2  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.739418864250183\n",
      "Inner Loss:  1.8290228247642517\n",
      "Inner Loss:  1.1036506295204163\n",
      "[[ 6  7 12]\n",
      " [ 3  2  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  4.389572739601135\n",
      "Inner Loss:  2.0478803515434265\n",
      "Inner Loss:  1.0935418009757996\n",
      "[[ 9 11 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.397552013397217\n",
      "Inner Loss:  2.0322832465171814\n",
      "Inner Loss:  1.1038565039634705\n",
      "[[10 10 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  4.323424577713013\n",
      "Inner Loss:  1.9709972143173218\n",
      "Inner Loss:  1.1227715611457825\n",
      "[[12  7 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.754905343055725\n",
      "Inner Loss:  1.8427792191505432\n",
      "Inner Loss:  1.1039156317710876\n",
      "[[10  4  6]\n",
      " [ 3  3  4]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.138196587562561\n",
      "Inner Loss:  1.9264000058174133\n",
      "Inner Loss:  1.0918189883232117\n",
      "[[ 8 10  9]\n",
      " [ 0  0  3]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.685445189476013\n",
      "Inner Loss:  1.8473886847496033\n",
      "Inner Loss:  1.0940375328063965\n",
      "[[7 5 2]\n",
      " [4 7 5]\n",
      " [0 0 0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.241346120834351\n",
      "Inner Loss:  2.0037145614624023\n",
      "Inner Loss:  1.1073918342590332\n",
      "[[ 5 14  9]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.126856327056885\n",
      "Inner Loss:  1.9243872165679932\n",
      "Inner Loss:  1.1027808785438538\n",
      "[[ 6 15  7]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  4.332036972045898\n",
      "Inner Loss:  2.000442624092102\n",
      "Inner Loss:  1.10093355178833\n",
      "[[12  6 11]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.57715106010437\n",
      "Inner Loss:  1.8188409805297852\n",
      "Inner Loss:  1.0866764187812805\n",
      "[[1 3 1]\n",
      " [6 6 7]\n",
      " [1 4 1]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  4.3857821226119995\n",
      "Inner Loss:  2.017400860786438\n",
      "Inner Loss:  1.0886945724487305\n",
      "[[ 9 11 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.560515403747559\n",
      "Inner Loss:  2.014045834541321\n",
      "Inner Loss:  1.0949804186820984\n",
      "[[13 12  5]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.3264888525009155\n",
      "Inner Loss:  1.9861176013946533\n",
      "Inner Loss:  1.0920907855033875\n",
      "[[12  7  9]\n",
      " [ 1  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.479872941970825\n",
      "Inner Loss:  2.028955578804016\n",
      "Inner Loss:  1.1284949779510498\n",
      "[[ 8 11 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.197948098182678\n",
      "Inner Loss:  1.9793423414230347\n",
      "Inner Loss:  1.0955355167388916\n",
      "[[11  5 13]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.5787746906280518\n",
      "Inner Loss:  1.8014388680458069\n",
      "Inner Loss:  1.1150183081626892\n",
      "[[4 4 8]\n",
      " [3 6 5]\n",
      " [0 0 0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.8953769207000732\n",
      "Inner Loss:  1.9238348007202148\n",
      "Inner Loss:  1.0901309251785278\n",
      "[[6 9 7]\n",
      " [2 5 1]\n",
      " [0 0 0]]\n",
      "Step: 5 \ttraining Acc: 0.3483333333333333\n",
      "\n",
      "-----------------Testing Mode-----------------\n",
      "\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.315940856933594\n",
      "Inner Loss:  1.9427350759506226\n",
      "Inner Loss:  1.116788625717163\n",
      "Inner Loss:  1.1877244114875793\n",
      "Inner Loss:  1.1236560344696045\n",
      "Inner Loss:  1.107570767402649\n",
      "Inner Loss:  1.1176904439926147\n",
      "Inner Loss:  1.1206929087638855\n",
      "Inner Loss:  1.1034432649612427\n",
      "Inner Loss:  1.0832242369651794\n",
      "[[ 6  6 11]\n",
      " [ 0  3  1]\n",
      " [ 0  1  2]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.005673170089722\n",
      "Inner Loss:  1.830320119857788\n",
      "Inner Loss:  1.1204155087471008\n",
      "Inner Loss:  1.2181500792503357\n",
      "Inner Loss:  1.120504379272461\n",
      "Inner Loss:  1.1199249625205994\n",
      "Inner Loss:  1.115520417690277\n",
      "Inner Loss:  1.101990282535553\n",
      "Inner Loss:  1.1109903454780579\n",
      "Inner Loss:  1.121592938899994\n",
      "[[ 5  4 11]\n",
      " [ 2  2  4]\n",
      " [ 0  2  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.243232846260071\n",
      "Inner Loss:  1.6115904450416565\n",
      "Inner Loss:  1.1060429811477661\n",
      "Inner Loss:  1.1659647226333618\n",
      "Inner Loss:  1.0945690870285034\n",
      "Inner Loss:  1.1025298833847046\n",
      "Inner Loss:  1.0901103019714355\n",
      "Inner Loss:  1.082836925983429\n",
      "Inner Loss:  1.114754855632782\n",
      "Inner Loss:  1.0931874513626099\n",
      "[[ 0  0  0]\n",
      " [ 9 11 10]\n",
      " [ 0  0  0]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.4718780517578125\n",
      "Inner Loss:  1.690950095653534\n",
      "Inner Loss:  1.0838215351104736\n",
      "Inner Loss:  1.1842783689498901\n",
      "Inner Loss:  1.1381973624229431\n",
      "Inner Loss:  1.11760675907135\n",
      "Inner Loss:  1.0912583470344543\n",
      "Inner Loss:  1.0914312601089478\n",
      "Inner Loss:  1.1158796548843384\n",
      "Inner Loss:  1.1047720313072205\n",
      "[[0 1 1]\n",
      " [5 9 7]\n",
      " [2 4 1]]\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.70742666721344\n",
      "Inner Loss:  1.8025553226470947\n",
      "Inner Loss:  1.138183832168579\n",
      "Inner Loss:  1.1975687146186829\n",
      "Inner Loss:  1.1046709418296814\n",
      "Inner Loss:  1.082575798034668\n",
      "Inner Loss:  1.107142984867096\n",
      "Inner Loss:  1.093828022480011\n",
      "Inner Loss:  1.0836623311042786\n",
      "Inner Loss:  1.0947261452674866\n",
      "[[1 3 1]\n",
      " [7 4 7]\n",
      " [4 1 2]]\n",
      "Step: 5 Test F1: 0.30666666666666664\n",
      "----Task 0 ----\n",
      "Inner Loss:  4.243376612663269\n",
      "Inner Loss:  1.969934105873108\n",
      "Inner Loss:  1.0936805605888367\n",
      "[[12  9  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.417740821838379\n",
      "Inner Loss:  1.9205910563468933\n",
      "Inner Loss:  1.115214467048645\n",
      "[[ 8 10 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.095404624938965\n",
      "Inner Loss:  1.8477656841278076\n",
      "Inner Loss:  1.0905262231826782\n",
      "[[ 8 11 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.746823310852051\n",
      "Inner Loss:  1.7905582785606384\n",
      "Inner Loss:  1.0987027883529663\n",
      "[[ 6 11  7]\n",
      " [ 3  1  2]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.174671530723572\n",
      "Inner Loss:  1.8590653538703918\n",
      "Inner Loss:  1.1183791160583496\n",
      "[[13  9  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.9053951501846313\n",
      "Inner Loss:  1.859031856060028\n",
      "Inner Loss:  1.1068596243858337\n",
      "[[ 4 12 12]\n",
      " [ 0  2  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.014023065567017\n",
      "Inner Loss:  1.836595594882965\n",
      "Inner Loss:  1.1391920447349548\n",
      "[[ 8 11 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.532853364944458\n",
      "Inner Loss:  1.7522217631340027\n",
      "Inner Loss:  1.1099902987480164\n",
      "[[4 7 9]\n",
      " [5 3 2]\n",
      " [0 0 0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.715395927429199\n",
      "Inner Loss:  1.769115149974823\n",
      "Inner Loss:  1.1248109340667725\n",
      "[[ 8  8 11]\n",
      " [ 0  2  1]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.660227656364441\n",
      "Inner Loss:  1.7631038427352905\n",
      "Inner Loss:  1.128131091594696\n",
      "[[ 9  6 12]\n",
      " [ 0  1  2]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.000790357589722\n",
      "Inner Loss:  1.8504883646965027\n",
      "Inner Loss:  1.1418029069900513\n",
      "[[12  7 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.568734288215637\n",
      "Inner Loss:  1.7061965465545654\n",
      "Inner Loss:  1.1249666213989258\n",
      "[[ 7  8 14]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.8042194843292236\n",
      "Inner Loss:  1.8194808959960938\n",
      "Inner Loss:  1.1083082556724548\n",
      "[[ 9  5 11]\n",
      " [ 2  1  2]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  3.372032642364502\n",
      "Inner Loss:  1.7184571027755737\n",
      "Inner Loss:  1.1156071424484253\n",
      "[[8 7 7]\n",
      " [4 2 2]\n",
      " [0 0 0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  4.696252822875977\n",
      "Inner Loss:  1.9811806678771973\n",
      "Inner Loss:  1.113114058971405\n",
      "[[ 7 11 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  4.232390522956848\n",
      "Inner Loss:  1.885501742362976\n",
      "Inner Loss:  1.1177378296852112\n",
      "[[ 5  8 16]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.6620906591415405\n",
      "Inner Loss:  1.7843546271324158\n",
      "Inner Loss:  1.1173434853553772\n",
      "[[ 2 11 10]\n",
      " [ 3  0  4]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  4.446670293807983\n",
      "Inner Loss:  1.940811276435852\n",
      "Inner Loss:  1.102796196937561\n",
      "[[12  9  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.761786937713623\n",
      "Inner Loss:  1.7459888458251953\n",
      "Inner Loss:  1.10194331407547\n",
      "[[12  9  7]\n",
      " [ 0  1  1]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.2497787475585938\n",
      "Inner Loss:  1.6666236519813538\n",
      "Inner Loss:  1.097284197807312\n",
      "[[5 7 7]\n",
      " [2 4 5]\n",
      " [0 0 0]]\n",
      "Step: 6 \ttraining Acc: 0.29500000000000004\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.826698660850525\n",
      "Inner Loss:  1.8823780417442322\n",
      "Inner Loss:  1.0917398929595947\n",
      "[[10 11  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  4.081032872200012\n",
      "Inner Loss:  1.8256609439849854\n",
      "Inner Loss:  1.1161455512046814\n",
      "[[11  9 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.6562317609786987\n",
      "Inner Loss:  1.7431280016899109\n",
      "Inner Loss:  1.1280455589294434\n",
      "[[13  7 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.044740319252014\n",
      "Inner Loss:  1.6666203141212463\n",
      "Inner Loss:  1.130288302898407\n",
      "[[ 8 10  8]\n",
      " [ 2  1  1]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.812628984451294\n",
      "Inner Loss:  1.7494361996650696\n",
      "Inner Loss:  1.077923059463501\n",
      "[[11 10  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.4077595472335815\n",
      "Inner Loss:  1.7055320739746094\n",
      "Inner Loss:  1.1092889904975891\n",
      "[[11 13  5]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.3184280395507812\n",
      "Inner Loss:  1.6986600160598755\n",
      "Inner Loss:  1.1172046065330505\n",
      "[[10  7 12]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  4.040754556655884\n",
      "Inner Loss:  1.8856124877929688\n",
      "Inner Loss:  1.0885381698608398\n",
      "[[ 7  8 15]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.2454510927200317\n",
      "Inner Loss:  1.689643144607544\n",
      "Inner Loss:  1.1141967177391052\n",
      "[[ 9 11  7]\n",
      " [ 1  2  0]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.912111759185791\n",
      "Inner Loss:  1.8253341317176819\n",
      "Inner Loss:  1.1065431833267212\n",
      "[[ 8 12 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.572471857070923\n",
      "Inner Loss:  1.728023886680603\n",
      "Inner Loss:  1.1183446049690247\n",
      "[[ 7 12 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.8720040321350098\n",
      "Inner Loss:  1.8342203497886658\n",
      "Inner Loss:  1.1066765189170837\n",
      "[[ 9  7 14]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  2.9518216848373413\n",
      "Inner Loss:  1.5384927988052368\n",
      "Inner Loss:  1.1240286827087402\n",
      "[[6 7 8]\n",
      " [4 3 2]\n",
      " [0 0 0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  3.944144129753113\n",
      "Inner Loss:  1.8197432160377502\n",
      "Inner Loss:  1.1011642217636108\n",
      "[[ 8 12 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.7396199703216553\n",
      "Inner Loss:  1.8128387928009033\n",
      "Inner Loss:  1.1191325187683105\n",
      "[[13  6 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.5014965534210205\n",
      "Inner Loss:  1.7932056188583374\n",
      "Inner Loss:  1.1062148213386536\n",
      "[[10  9  9]\n",
      " [ 1  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.897902727127075\n",
      "Inner Loss:  1.8732802867889404\n",
      "Inner Loss:  1.091415524482727\n",
      "[[10  9 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.8226784467697144\n",
      "Inner Loss:  1.7985312342643738\n",
      "Inner Loss:  1.092638909816742\n",
      "[[13  7 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.725670337677002\n",
      "Inner Loss:  1.8298510909080505\n",
      "Inner Loss:  1.104061484336853\n",
      "[[ 5 11 13]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  2.746673345565796\n",
      "Inner Loss:  1.5224188566207886\n",
      "Inner Loss:  1.0952726602554321\n",
      "[[9 6 9]\n",
      " [3 2 1]\n",
      " [0 0 0]]\n",
      "Step: 7 \ttraining Acc: 0.32833333333333325\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.0850430727005005\n",
      "Inner Loss:  1.684261977672577\n",
      "Inner Loss:  1.1429282426834106\n",
      "[[ 7 12 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.4954445362091064\n",
      "Inner Loss:  1.7995913624763489\n",
      "Inner Loss:  1.0944281816482544\n",
      "[[ 6  8 16]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.3099544048309326\n",
      "Inner Loss:  1.753077507019043\n",
      "Inner Loss:  1.1222647428512573\n",
      "[[ 9  5 16]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  2.975589871406555\n",
      "Inner Loss:  1.675898790359497\n",
      "Inner Loss:  1.1247197389602661\n",
      "[[ 9 12  8]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  2.925045967102051\n",
      "Inner Loss:  1.566111981868744\n",
      "Inner Loss:  1.0857389569282532\n",
      "[[12  7 10]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.067832350730896\n",
      "Inner Loss:  1.6430984735488892\n",
      "Inner Loss:  1.1285545229911804\n",
      "[[ 6 12 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.1973819732666016\n",
      "Inner Loss:  1.691531479358673\n",
      "Inner Loss:  1.0971750020980835\n",
      "[[10 12  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.0565614700317383\n",
      "Inner Loss:  1.6424715518951416\n",
      "Inner Loss:  1.110158920288086\n",
      "[[11  9 10]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.2993712425231934\n",
      "Inner Loss:  1.7353611588478088\n",
      "Inner Loss:  1.1282164454460144\n",
      "[[13  8  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  2.3787811994552612\n",
      "Inner Loss:  1.4060621857643127\n",
      "Inner Loss:  1.104398488998413\n",
      "[[1 1 2]\n",
      " [4 3 1]\n",
      " [6 7 5]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  4.088206171989441\n",
      "Inner Loss:  1.9624905586242676\n",
      "Inner Loss:  1.0515925288200378\n",
      "[[11 10  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.136399745941162\n",
      "Inner Loss:  1.6925185918807983\n",
      "Inner Loss:  1.0852272510528564\n",
      "[[13  8  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.703656792640686\n",
      "Inner Loss:  1.8599449396133423\n",
      "Inner Loss:  1.116587519645691\n",
      "[[11  8 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  2.9319419860839844\n",
      "Inner Loss:  1.6373544335365295\n",
      "Inner Loss:  1.093695878982544\n",
      "[[12 10  7]\n",
      " [ 1  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.021330952644348\n",
      "Inner Loss:  1.6502866744995117\n",
      "Inner Loss:  1.1273857951164246\n",
      "[[ 5 14 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.1396496295928955\n",
      "Inner Loss:  1.6566487550735474\n",
      "Inner Loss:  1.1043742895126343\n",
      "[[14 10  5]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.1082106828689575\n",
      "Inner Loss:  1.6824083924293518\n",
      "Inner Loss:  1.1271744966506958\n",
      "[[11 10  8]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.0360658168792725\n",
      "Inner Loss:  1.6644896864891052\n",
      "Inner Loss:  1.1075835824012756\n",
      "[[ 8  5 17]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  2.8928308486938477\n",
      "Inner Loss:  1.6261004209518433\n",
      "Inner Loss:  1.145779311656952\n",
      "[[ 7  9 13]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.9607690572738647\n",
      "Inner Loss:  1.9392760396003723\n",
      "Inner Loss:  1.0795611143112183\n",
      "[[ 5  9 16]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "Step: 8 \ttraining Acc: 0.32166666666666666\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.887677550315857\n",
      "Inner Loss:  2.004953145980835\n",
      "Inner Loss:  1.1057544350624084\n",
      "[[ 9  9 12]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.325051188468933\n",
      "Inner Loss:  1.834493637084961\n",
      "Inner Loss:  1.10348778963089\n",
      "[[ 8 11 11]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  2.265282154083252\n",
      "Inner Loss:  1.4746421575546265\n",
      "Inner Loss:  1.093232274055481\n",
      "[[3 1 2]\n",
      " [2 2 3]\n",
      " [5 9 3]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  2.927057981491089\n",
      "Inner Loss:  1.6945547461509705\n",
      "Inner Loss:  1.1205315589904785\n",
      "[[11  5  7]\n",
      " [ 1  0  0]\n",
      " [ 2  1  3]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.322202444076538\n",
      "Inner Loss:  1.8756529092788696\n",
      "Inner Loss:  1.105403482913971\n",
      "[[11  6 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.0146809816360474\n",
      "Inner Loss:  1.7067208886146545\n",
      "Inner Loss:  1.1085326671600342\n",
      "[[ 6 10 14]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.41903555393219\n",
      "Inner Loss:  1.8746778964996338\n",
      "Inner Loss:  1.123010277748108\n",
      "[[11 10  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.3152785301208496\n",
      "Inner Loss:  1.837823212146759\n",
      "Inner Loss:  1.1343039870262146\n",
      "[[ 6 11 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.033373475074768\n",
      "Inner Loss:  1.7101939916610718\n",
      "Inner Loss:  1.139025092124939\n",
      "[[ 8 12  8]\n",
      " [ 0  0  1]\n",
      " [ 0  1  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.4986807107925415\n",
      "Inner Loss:  1.9099274277687073\n",
      "Inner Loss:  1.1007004380226135\n",
      "[[13 10  7]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  2.571902632713318\n",
      "Inner Loss:  1.5683326125144958\n",
      "Inner Loss:  1.10373455286026\n",
      "[[7 7 8]\n",
      " [2 0 3]\n",
      " [2 1 0]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  2.580173134803772\n",
      "Inner Loss:  1.5472909808158875\n",
      "Inner Loss:  1.0714993476867676\n",
      "[[ 0  1  2]\n",
      " [ 0  0  0]\n",
      " [ 9 10  8]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  2.9884278774261475\n",
      "Inner Loss:  1.676002323627472\n",
      "Inner Loss:  1.1262245774269104\n",
      "[[ 9 11  9]\n",
      " [ 0  0  1]\n",
      " [ 0  0  0]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  2.9355839490890503\n",
      "Inner Loss:  1.7169808149337769\n",
      "Inner Loss:  1.100878357887268\n",
      "[[16 10  4]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  2.733951449394226\n",
      "Inner Loss:  1.6651608347892761\n",
      "Inner Loss:  1.1393691897392273\n",
      "[[4 6 3]\n",
      " [0 0 0]\n",
      " [6 5 6]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  2.765857696533203\n",
      "Inner Loss:  1.6331594586372375\n",
      "Inner Loss:  1.107797920703888\n",
      "[[12  6  7]\n",
      " [ 0  0  0]\n",
      " [ 2  3  0]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.2184786796569824\n",
      "Inner Loss:  1.793584167957306\n",
      "Inner Loss:  1.1075465083122253\n",
      "[[11 10  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  2.910797119140625\n",
      "Inner Loss:  1.6950557827949524\n",
      "Inner Loss:  1.1019665002822876\n",
      "[[ 9 13  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.1115951538085938\n",
      "Inner Loss:  1.7670142650604248\n",
      "Inner Loss:  1.1085038781166077\n",
      "[[10 11  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  2.558992028236389\n",
      "Inner Loss:  1.501478672027588\n",
      "Inner Loss:  1.0883009433746338\n",
      "[[ 7 10  5]\n",
      " [ 2  2  3]\n",
      " [ 0  0  1]]\n",
      "Step: 9 \ttraining Acc: 0.3266666666666666\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.078730344772339\n",
      "Inner Loss:  1.843315303325653\n",
      "Inner Loss:  1.134307861328125\n",
      "[[ 9 12  5]\n",
      " [ 1  1  1]\n",
      " [ 0  1  0]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  2.7319732904434204\n",
      "Inner Loss:  1.7045899629592896\n",
      "Inner Loss:  1.1431840062141418\n",
      "[[5 4 5]\n",
      " [3 0 1]\n",
      " [3 5 4]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.182953715324402\n",
      "Inner Loss:  1.8900775909423828\n",
      "Inner Loss:  1.1544324159622192\n",
      "[[6 7 7]\n",
      " [0 0 0]\n",
      " [3 4 3]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.406240940093994\n",
      "Inner Loss:  1.968773365020752\n",
      "Inner Loss:  1.1381981372833252\n",
      "[[12 11  6]\n",
      " [ 0  0  0]\n",
      " [ 0  1  0]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.3653523921966553\n",
      "Inner Loss:  1.9798685312271118\n",
      "Inner Loss:  1.1538079977035522\n",
      "[[3 3 4]\n",
      " [0 0 0]\n",
      " [7 7 6]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.4283875226974487\n",
      "Inner Loss:  2.0331846475601196\n",
      "Inner Loss:  1.1663178205490112\n",
      "[[4 3 4]\n",
      " [0 0 0]\n",
      " [8 6 5]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.6157820224761963\n",
      "Inner Loss:  2.1126375794410706\n",
      "Inner Loss:  1.2113822102546692\n",
      "[[ 6 15  9]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.312516927719116\n",
      "Inner Loss:  1.9919411540031433\n",
      "Inner Loss:  1.1599934697151184\n",
      "[[4 7 5]\n",
      " [0 0 1]\n",
      " [5 4 4]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.5867297649383545\n",
      "Inner Loss:  2.062272548675537\n",
      "Inner Loss:  1.1465038061141968\n",
      "[[10  7 13]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.4354300498962402\n",
      "Inner Loss:  1.9722272753715515\n",
      "Inner Loss:  1.163658320903778\n",
      "[[16  9  5]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.432405471801758\n",
      "Inner Loss:  1.9737547039985657\n",
      "Inner Loss:  1.1657459139823914\n",
      "[[8 4 9]\n",
      " [0 0 0]\n",
      " [2 3 4]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  2.9845110177993774\n",
      "Inner Loss:  1.866984486579895\n",
      "Inner Loss:  1.1493179202079773\n",
      "[[2 5 2]\n",
      " [0 0 0]\n",
      " [8 5 8]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  2.8695541620254517\n",
      "Inner Loss:  1.7692736387252808\n",
      "Inner Loss:  1.170786201953888\n",
      "[[5 3 4]\n",
      " [0 0 0]\n",
      " [6 4 8]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  2.8413290977478027\n",
      "Inner Loss:  1.7670401334762573\n",
      "Inner Loss:  1.1690481305122375\n",
      "[[8 3 8]\n",
      " [0 1 0]\n",
      " [3 3 4]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.2735953330993652\n",
      "Inner Loss:  1.9345476627349854\n",
      "Inner Loss:  1.1417226791381836\n",
      "[[10  8 10]\n",
      " [ 0  0  0]\n",
      " [ 0  2  0]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.527341842651367\n",
      "Inner Loss:  2.0291903614997864\n",
      "Inner Loss:  1.1755316853523254\n",
      "[[ 6  8 12]\n",
      " [ 0  0  0]\n",
      " [ 1  1  2]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  2.7012813091278076\n",
      "Inner Loss:  1.7187336683273315\n",
      "Inner Loss:  1.1229090690612793\n",
      "[[5 7 1]\n",
      " [2 2 6]\n",
      " [3 4 0]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.4855791330337524\n",
      "Inner Loss:  2.0445539355278015\n",
      "Inner Loss:  1.1529752612113953\n",
      "[[10  8 11]\n",
      " [ 0  0  0]\n",
      " [ 1  0  0]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  2.724974036216736\n",
      "Inner Loss:  1.6872819662094116\n",
      "Inner Loss:  1.1533939838409424\n",
      "[[ 0  2  1]\n",
      " [ 1  0  1]\n",
      " [11  7  7]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.137667179107666\n",
      "Inner Loss:  1.8481963276863098\n",
      "Inner Loss:  1.1419602036476135\n",
      "[[11  5 13]\n",
      " [ 0  1  0]\n",
      " [ 0  0  0]]\n",
      "Step: 10 \ttraining Acc: 0.33333333333333337\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.587448835372925\n",
      "Inner Loss:  2.1520580053329468\n",
      "Inner Loss:  1.2684754133224487\n",
      "[[ 0  1  2]\n",
      " [ 2  0  0]\n",
      " [ 7  7 11]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.1134785413742065\n",
      "Inner Loss:  1.98517507314682\n",
      "Inner Loss:  1.2635911107063293\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 12 10]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.609403371810913\n",
      "Inner Loss:  2.176692843437195\n",
      "Inner Loss:  1.2847050428390503\n",
      "[[ 0  1  1]\n",
      " [ 0  0  0]\n",
      " [10  4 14]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.126187324523926\n",
      "Inner Loss:  1.9619532823562622\n",
      "Inner Loss:  1.2695152759552002\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 10 11]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.6013699769973755\n",
      "Inner Loss:  2.1865060329437256\n",
      "Inner Loss:  1.286454439163208\n",
      "[[ 1  0  0]\n",
      " [ 0  0  0]\n",
      " [12  8  9]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.4895801544189453\n",
      "Inner Loss:  2.1033077239990234\n",
      "Inner Loss:  1.272202968597412\n",
      "[[5 1 3]\n",
      " [3 1 1]\n",
      " [7 2 7]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.695764899253845\n",
      "Inner Loss:  2.2846107482910156\n",
      "Inner Loss:  1.285801351070404\n",
      "[[ 1  2  0]\n",
      " [ 0  0  0]\n",
      " [ 9 10  8]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.2082196474075317\n",
      "Inner Loss:  2.010594964027405\n",
      "Inner Loss:  1.2541324496269226\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9  5 16]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  2.722761869430542\n",
      "Inner Loss:  1.7652080655097961\n",
      "Inner Loss:  1.23549085855484\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [11  6 13]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.7274346351623535\n",
      "Inner Loss:  2.2348657846450806\n",
      "Inner Loss:  1.2834465503692627\n",
      "[[5 2 0]\n",
      " [0 0 2]\n",
      " [7 6 8]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.429957151412964\n",
      "Inner Loss:  2.111660599708557\n",
      "Inner Loss:  1.2925028204917908\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  6 12]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.7176660299301147\n",
      "Inner Loss:  2.2443597316741943\n",
      "Inner Loss:  1.3103920817375183\n",
      "[[ 2  3  0]\n",
      " [ 2  0  0]\n",
      " [ 7  6 10]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  3.274885058403015\n",
      "Inner Loss:  2.0369229912757874\n",
      "Inner Loss:  1.232369065284729\n",
      "[[ 1  2  0]\n",
      " [ 1  0  1]\n",
      " [ 7  7 11]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  3.7012559175491333\n",
      "Inner Loss:  2.2355486154556274\n",
      "Inner Loss:  1.3044214248657227\n",
      "[[ 2  1  2]\n",
      " [ 0  1  2]\n",
      " [11  7  4]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  2.6421267986297607\n",
      "Inner Loss:  1.736079454421997\n",
      "Inner Loss:  1.2381150722503662\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [10  9 11]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.641855835914612\n",
      "Inner Loss:  2.203210473060608\n",
      "Inner Loss:  1.2729861736297607\n",
      "[[1 4 3]\n",
      " [2 1 0]\n",
      " [7 3 9]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.7454514503479004\n",
      "Inner Loss:  2.274491310119629\n",
      "Inner Loss:  1.2947456240653992\n",
      "[[1 3 0]\n",
      " [0 3 1]\n",
      " [8 7 7]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.1779805421829224\n",
      "Inner Loss:  1.9974114894866943\n",
      "Inner Loss:  1.2387129068374634\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  7 11]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.1704994440078735\n",
      "Inner Loss:  1.9978615641593933\n",
      "Inner Loss:  1.24928617477417\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12  8 10]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.6990010738372803\n",
      "Inner Loss:  2.1875306367874146\n",
      "Inner Loss:  1.2521952986717224\n",
      "[[7 2 4]\n",
      " [3 1 2]\n",
      " [7 0 4]]\n",
      "Step: 11 \ttraining Acc: 0.38166666666666665\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.134412169456482\n",
      "Inner Loss:  2.042646646499634\n",
      "Inner Loss:  1.3496208786964417\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [13 10  7]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.6137248277664185\n",
      "Inner Loss:  2.2784470319747925\n",
      "Inner Loss:  1.3959726691246033\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [14  7  9]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.0545196533203125\n",
      "Inner Loss:  2.0520198345184326\n",
      "Inner Loss:  1.3491594195365906\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 10 12]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.6881673336029053\n",
      "Inner Loss:  2.327181339263916\n",
      "Inner Loss:  1.3935973644256592\n",
      "[[ 0  0  0]\n",
      " [ 0  0  1]\n",
      " [ 7 11 11]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.3911575078964233\n",
      "Inner Loss:  2.1242297887802124\n",
      "Inner Loss:  1.3238288164138794\n",
      "[[ 0  0  0]\n",
      " [ 0  3  0]\n",
      " [ 9 14  4]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  2.983907103538513\n",
      "Inner Loss:  1.9526864886283875\n",
      "Inner Loss:  1.2776822447776794\n",
      "[[ 0  0  0]\n",
      " [ 0  2  0]\n",
      " [17  8  3]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.0044230222702026\n",
      "Inner Loss:  1.9746785163879395\n",
      "Inner Loss:  1.3013235926628113\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 12 10]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.7793807983398438\n",
      "Inner Loss:  2.3755791187286377\n",
      "Inner Loss:  1.4013957977294922\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9 13  8]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.0265731811523438\n",
      "Inner Loss:  2.0009570717811584\n",
      "Inner Loss:  1.3072123527526855\n",
      "[[ 0  0  0]\n",
      " [ 1  0  0]\n",
      " [14  9  6]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.393445134162903\n",
      "Inner Loss:  2.1550824642181396\n",
      "Inner Loss:  1.3703727722167969\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8 13  9]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.6833466291427612\n",
      "Inner Loss:  2.328838348388672\n",
      "Inner Loss:  1.3822215795516968\n",
      "[[ 0  0  0]\n",
      " [ 0  0  1]\n",
      " [ 5 15  9]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.3956881761550903\n",
      "Inner Loss:  2.1647945642471313\n",
      "Inner Loss:  1.348379671573639\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 9  9 12]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  2.8768078088760376\n",
      "Inner Loss:  1.895645260810852\n",
      "Inner Loss:  1.2802503108978271\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 8  7 15]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  3.567145586013794\n",
      "Inner Loss:  2.2784221172332764\n",
      "Inner Loss:  1.3932132720947266\n",
      "[[ 0  0  0]\n",
      " [ 1  2  0]\n",
      " [ 6 11 10]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  2.9295051097869873\n",
      "Inner Loss:  1.9635320901870728\n",
      "Inner Loss:  1.2997230887413025\n",
      "[[ 0  0  0]\n",
      " [ 1  0  3]\n",
      " [ 7 12  7]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.8971757888793945\n",
      "Inner Loss:  2.4327749013900757\n",
      "Inner Loss:  1.4123465418815613\n",
      "[[ 0  1  0]\n",
      " [ 1  1  0]\n",
      " [ 7  9 11]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  3.9591431617736816\n",
      "Inner Loss:  2.4358112812042236\n",
      "Inner Loss:  1.3981242179870605\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [12 12  6]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.6882067918777466\n",
      "Inner Loss:  2.309396505355835\n",
      "Inner Loss:  1.386311650276184\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 7  8 15]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.572418451309204\n",
      "Inner Loss:  2.2593228816986084\n",
      "Inner Loss:  1.3876089453697205\n",
      "[[ 0  0  0]\n",
      " [ 1  0  1]\n",
      " [ 9  9 10]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.46967089176178\n",
      "Inner Loss:  2.2124868631362915\n",
      "Inner Loss:  1.3689934015274048\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 6  8 16]]\n",
      "Step: 12 \ttraining Acc: 0.32999999999999996\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.2525609731674194\n",
      "Inner Loss:  2.1402558088302612\n",
      "Inner Loss:  1.3956082463264465\n",
      "[[ 0  0  0]\n",
      " [ 1  0  2]\n",
      " [ 6 10 11]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.3087856769561768\n",
      "Inner Loss:  2.16330349445343\n",
      "Inner Loss:  1.4239473938941956\n",
      "[[0 0 0]\n",
      " [4 3 1]\n",
      " [7 6 9]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  4.003870844841003\n",
      "Inner Loss:  2.5043150186538696\n",
      "Inner Loss:  1.5147606134414673\n",
      "[[0 0 0]\n",
      " [1 7 3]\n",
      " [6 6 7]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.2798932790756226\n",
      "Inner Loss:  2.1362829208374023\n",
      "Inner Loss:  1.4011154174804688\n",
      "[[0 0 0]\n",
      " [6 2 2]\n",
      " [4 7 9]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  3.234027147293091\n",
      "Inner Loss:  2.074804365634918\n",
      "Inner Loss:  1.4294134974479675\n",
      "[[ 0  0  0]\n",
      " [ 3  0  1]\n",
      " [11  6  9]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.5518821477890015\n",
      "Inner Loss:  2.2647082805633545\n",
      "Inner Loss:  1.4590034484863281\n",
      "[[ 0  0  0]\n",
      " [ 2  2  1]\n",
      " [12  6  7]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  3.643896698951721\n",
      "Inner Loss:  2.342216730117798\n",
      "Inner Loss:  1.4680165648460388\n",
      "[[ 0  0  0]\n",
      " [ 1  2  0]\n",
      " [ 8  8 11]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.773242950439453\n",
      "Inner Loss:  2.391204833984375\n",
      "Inner Loss:  1.4843826293945312\n",
      "[[ 0  0  0]\n",
      " [ 2  4  2]\n",
      " [10  6  6]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.722155809402466\n",
      "Inner Loss:  2.343768358230591\n",
      "Inner Loss:  1.4730734825134277\n",
      "[[0 0 0]\n",
      " [4 1 6]\n",
      " [6 8 5]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.041083455085754\n",
      "Inner Loss:  2.5793906450271606\n",
      "Inner Loss:  1.486266851425171\n",
      "[[ 0  0  0]\n",
      " [ 1  4  0]\n",
      " [11  8  6]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.611067533493042\n",
      "Inner Loss:  2.3001827001571655\n",
      "Inner Loss:  1.4051048159599304\n",
      "[[ 0  0  0]\n",
      " [ 2  0  0]\n",
      " [ 8 10 10]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.4202075004577637\n",
      "Inner Loss:  2.204247772693634\n",
      "Inner Loss:  1.4204810857772827\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [13  6 10]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  2.9326561093330383\n",
      "Inner Loss:  1.967078149318695\n",
      "Inner Loss:  1.365123987197876\n",
      "[[ 0  0  0]\n",
      " [ 1  2  1]\n",
      " [12  9  5]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  2.9095449447631836\n",
      "Inner Loss:  1.9637206196784973\n",
      "Inner Loss:  1.3771949410438538\n",
      "[[ 0  0  0]\n",
      " [ 0  1  1]\n",
      " [ 8 13  7]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  2.913988947868347\n",
      "Inner Loss:  1.9673414826393127\n",
      "Inner Loss:  1.3647267818450928\n",
      "[[0 0 0]\n",
      " [3 3 1]\n",
      " [6 9 8]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.427870750427246\n",
      "Inner Loss:  2.249763011932373\n",
      "Inner Loss:  1.467807650566101\n",
      "[[ 0  0  0]\n",
      " [ 2  3  2]\n",
      " [ 3 10 10]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  4.253752946853638\n",
      "Inner Loss:  2.622072219848633\n",
      "Inner Loss:  1.5213946104049683\n",
      "[[ 0  0  0]\n",
      " [ 0  1  1]\n",
      " [10 12  6]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.4935789108276367\n",
      "Inner Loss:  2.282735824584961\n",
      "Inner Loss:  1.4700348377227783\n",
      "[[0 0 0]\n",
      " [3 3 4]\n",
      " [4 8 8]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  3.782675862312317\n",
      "Inner Loss:  2.393961191177368\n",
      "Inner Loss:  1.4674137234687805\n",
      "[[ 0  0  0]\n",
      " [ 2  1  1]\n",
      " [10  9  7]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.4734479188919067\n",
      "Inner Loss:  2.227620840072632\n",
      "Inner Loss:  1.43463534116745\n",
      "[[ 0  0  0]\n",
      " [ 2  0  3]\n",
      " [ 7  5 13]]\n",
      "Step: 13 \ttraining Acc: 0.33999999999999997\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.6882898807525635\n",
      "Inner Loss:  2.367956757545471\n",
      "Inner Loss:  1.4395410418510437\n",
      "[[0 0 0]\n",
      " [3 3 5]\n",
      " [5 7 7]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.326144576072693\n",
      "Inner Loss:  2.2035534381866455\n",
      "Inner Loss:  1.437056303024292\n",
      "[[0 0 0]\n",
      " [4 3 2]\n",
      " [7 7 7]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.4494839906692505\n",
      "Inner Loss:  2.2075064182281494\n",
      "Inner Loss:  1.4361241459846497\n",
      "[[ 0  0  0]\n",
      " [ 3  1  0]\n",
      " [ 9 10  7]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.7577327489852905\n",
      "Inner Loss:  2.361160635948181\n",
      "Inner Loss:  1.4632218480110168\n",
      "[[0 0 0]\n",
      " [1 7 6]\n",
      " [5 8 3]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  4.145373344421387\n",
      "Inner Loss:  2.550103187561035\n",
      "Inner Loss:  1.5384587049484253\n",
      "[[ 0  0  0]\n",
      " [ 0  1  0]\n",
      " [11  8 10]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.462808609008789\n",
      "Inner Loss:  2.233911395072937\n",
      "Inner Loss:  1.4671411514282227\n",
      "[[0 0 0]\n",
      " [4 3 4]\n",
      " [4 6 9]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.589357137680054\n",
      "Inner Loss:  2.753037452697754\n",
      "Inner Loss:  1.5599344968795776\n",
      "[[ 0  0  0]\n",
      " [ 0  1  1]\n",
      " [ 6 13  9]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.5725213289260864\n",
      "Inner Loss:  2.298166036605835\n",
      "Inner Loss:  1.4774853587150574\n",
      "[[0 0 0]\n",
      " [2 6 5]\n",
      " [6 6 5]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.36971914768219\n",
      "Inner Loss:  2.2036041021347046\n",
      "Inner Loss:  1.3824689388275146\n",
      "[[0 0 0]\n",
      " [5 5 8]\n",
      " [6 3 3]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  3.609689950942993\n",
      "Inner Loss:  2.2732701301574707\n",
      "Inner Loss:  1.4416441321372986\n",
      "[[0 0 0]\n",
      " [6 5 4]\n",
      " [3 6 6]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.2559622526168823\n",
      "Inner Loss:  2.0965574383735657\n",
      "Inner Loss:  1.386051893234253\n",
      "[[0 0 0]\n",
      " [4 2 3]\n",
      " [6 8 7]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.7137876749038696\n",
      "Inner Loss:  2.3803272247314453\n",
      "Inner Loss:  1.4785519242286682\n",
      "[[0 0 0]\n",
      " [2 4 7]\n",
      " [4 6 7]]\n",
      "----Task 12 ----\n",
      "Inner Loss:  2.8653817176818848\n",
      "Inner Loss:  1.9405292868614197\n",
      "Inner Loss:  1.3627629280090332\n",
      "[[ 0  0  0]\n",
      " [ 5  4  4]\n",
      " [10  3  4]]\n",
      "----Task 13 ----\n",
      "Inner Loss:  3.60406494140625\n",
      "Inner Loss:  2.303831458091736\n",
      "Inner Loss:  1.472453236579895\n",
      "[[0 0 0]\n",
      " [7 1 5]\n",
      " [6 4 7]]\n",
      "----Task 14 ----\n",
      "Inner Loss:  3.5605170726776123\n",
      "Inner Loss:  2.3025195598602295\n",
      "Inner Loss:  1.4770650267601013\n",
      "[[0 0 0]\n",
      " [4 3 5]\n",
      " [5 6 7]]\n",
      "----Task 15 ----\n",
      "Inner Loss:  3.942610263824463\n",
      "Inner Loss:  2.468808174133301\n",
      "Inner Loss:  1.5123738050460815\n",
      "[[ 0  0  0]\n",
      " [ 3  2  3]\n",
      " [ 5  7 10]]\n",
      "----Task 16 ----\n",
      "Inner Loss:  2.4829782247543335\n",
      "Inner Loss:  1.6895038485527039\n",
      "Inner Loss:  1.2806028127670288\n",
      "[[ 0  0  0]\n",
      " [ 3  0  3]\n",
      " [ 9 10  5]]\n",
      "----Task 17 ----\n",
      "Inner Loss:  3.5158870220184326\n",
      "Inner Loss:  2.243601441383362\n",
      "Inner Loss:  1.4749637246131897\n",
      "[[0 0 0]\n",
      " [3 7 4]\n",
      " [3 9 4]]\n",
      "----Task 18 ----\n",
      "Inner Loss:  4.39003050327301\n",
      "Inner Loss:  2.6765120029449463\n",
      "Inner Loss:  1.508832037448883\n",
      "[[ 0  0  0]\n",
      " [ 3  2  4]\n",
      " [10  3  8]]\n",
      "----Task 19 ----\n",
      "Inner Loss:  3.719227910041809\n",
      "Inner Loss:  2.3804588317871094\n",
      "Inner Loss:  1.4967790246009827\n",
      "[[ 0  0  0]\n",
      " [ 3  0  3]\n",
      " [ 4 11  9]]\n",
      "Step: 14 \ttraining Acc: 0.3233333333333333\n",
      "----Task 0 ----\n",
      "Inner Loss:  3.9092066287994385\n",
      "Inner Loss:  2.4471770524978638\n",
      "Inner Loss:  1.4593935012817383\n",
      "[[ 0  0  0]\n",
      " [ 3  3 10]\n",
      " [ 5  3  6]]\n",
      "----Task 1 ----\n",
      "Inner Loss:  3.6162562370300293\n",
      "Inner Loss:  2.2221267223358154\n",
      "Inner Loss:  1.3556597232818604\n",
      "[[ 0  0  0]\n",
      " [ 1  1  0]\n",
      " [ 7  9 12]]\n",
      "----Task 2 ----\n",
      "Inner Loss:  3.3969759941101074\n",
      "Inner Loss:  2.1651244163513184\n",
      "Inner Loss:  1.386704444885254\n",
      "[[0 0 0]\n",
      " [3 8 3]\n",
      " [3 4 9]]\n",
      "----Task 3 ----\n",
      "Inner Loss:  3.9428786039352417\n",
      "Inner Loss:  2.4348371028900146\n",
      "Inner Loss:  1.4703248739242554\n",
      "[[0 0 0]\n",
      " [4 3 4]\n",
      " [7 7 5]]\n",
      "----Task 4 ----\n",
      "Inner Loss:  2.7578253746032715\n",
      "Inner Loss:  1.8526666164398193\n",
      "Inner Loss:  1.304843544960022\n",
      "[[0 0 0]\n",
      " [8 4 3]\n",
      " [4 6 5]]\n",
      "----Task 5 ----\n",
      "Inner Loss:  3.4217514991760254\n",
      "Inner Loss:  2.1553072929382324\n",
      "Inner Loss:  1.4186094403266907\n",
      "[[0 0 0]\n",
      " [2 1 4]\n",
      " [8 9 6]]\n",
      "----Task 6 ----\n",
      "Inner Loss:  4.269695520401001\n",
      "Inner Loss:  2.568075180053711\n",
      "Inner Loss:  1.4774919152259827\n",
      "[[ 0  0  0]\n",
      " [ 1  3  3]\n",
      " [ 7 12  4]]\n",
      "----Task 7 ----\n",
      "Inner Loss:  3.955793857574463\n",
      "Inner Loss:  2.4148765802383423\n",
      "Inner Loss:  1.4729499220848083\n",
      "[[0 0 0]\n",
      " [8 7 5]\n",
      " [3 4 3]]\n",
      "----Task 8 ----\n",
      "Inner Loss:  3.5378432273864746\n",
      "Inner Loss:  2.2621034383773804\n",
      "Inner Loss:  1.4299981594085693\n",
      "[[0 0 0]\n",
      " [3 5 4]\n",
      " [7 6 5]]\n",
      "----Task 9 ----\n",
      "Inner Loss:  4.206563591957092\n",
      "Inner Loss:  2.5405471324920654\n",
      "Inner Loss:  1.4815390706062317\n",
      "[[0 0 0]\n",
      " [4 2 5]\n",
      " [1 9 9]]\n",
      "----Task 10 ----\n",
      "Inner Loss:  3.465195417404175\n",
      "Inner Loss:  2.2598461508750916\n",
      "Inner Loss:  1.4296226501464844\n",
      "[[0 0 0]\n",
      " [6 1 7]\n",
      " [5 4 7]]\n",
      "----Task 11 ----\n",
      "Inner Loss:  3.6837788820266724\n",
      "Inner Loss:  2.2880990505218506\n",
      "Inner Loss:  1.4248913526535034\n"
     ]
    }
   ],
   "source": [
    "learner = Learner(args)\n",
    "    \n",
    "test = MetaTask(test_examples, num_task = args.num_task_test, k_support=args.k_spt,k_query=args.k_qry, tokenizer = tokenizer)\n",
    "\n",
    "global_step = 0\n",
    "#for epoch in range(args.epoch):\n",
    "for epoch in range(args.meta_epoch):\n",
    "        train = MetaTask(train_examples, num_task = args.num_task_train, k_support=args.k_spt, \n",
    "                         k_query=args.k_qry, tokenizer = tokenizer)\n",
    "\n",
    "        db = create_batch_of_tasks(train, is_shuffle = True, batch_size = args.outer_batch_size)\n",
    "\n",
    "        for step, task_batch in enumerate(db):\n",
    "\n",
    "            acc = learner(task_batch)\n",
    "\n",
    "            print('Step:', step, '\\ttraining Acc:', acc)\n",
    "\n",
    "            if global_step % 10 == 0:\n",
    "                random_seed(123)\n",
    "                print(\"\\n-----------------Testing Mode-----------------\\n\")\n",
    "                db_test = create_batch_of_tasks(test, is_shuffle = False, batch_size = 1)\n",
    "                acc_all_test = []\n",
    "\n",
    "                for test_batch in db_test:\n",
    "                    acc = learner(test_batch, training = False)\n",
    "                    acc_all_test.append(acc)\n",
    "\n",
    "                print('Step:', step, 'Test F1:', np.mean(acc_all_test))\n",
    "\n",
    "                random_seed(int(time.time() % 10))\n",
    "\n",
    "            global_step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649e33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
